{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebba3a0d-7eef-4848-a00b-9e06d5c80aa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.13 (you have 1.4.12). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Local dep\n",
    "project_dir = '/data/konrad/workspace'\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from helpers.datasets import CalfCenterFaceDataset\n",
    "from helpers.helpers import get_indices, uniform_sample_with_values, load_face_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf191360-2536-4052-a1ed-b2a26099c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox_gallery(image_df, n_cols=5):\n",
    "    n_images = image_df.shape[0]\n",
    "    n_rows = n_images // n_cols + int(n_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(20, n_rows * 4))\n",
    "    for i, row in image_df.iterrows():\n",
    "        img = Image.open(row[\"path\"])\n",
    "        # plt.subplot(n_rows, n_cols, i + 1)\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        # ax = plt.gca()\n",
    "        score = row[\"conf\"]\n",
    "        box_x = row[\"box_x\"]\n",
    "        box_y = row[\"box_y\"]\n",
    "        box_width = row[\"box_width\"]\n",
    "        box_height = row[\"box_height\"]\n",
    "        box_x = box_x - (box_width / 2)\n",
    "        box_y = box_y - (box_height / 2)\n",
    "        rect = plt.Rectangle((box_x, box_y), box_width, box_height, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(box_x, box_y - 10, f' {score:.2f}', color='red', fontsize=12, backgroundcolor='white')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def apply_transformations(image, bbox, transforms):\n",
    "    transformed = transforms(image=image, bboxes=[bbox], category_ids=[0])\n",
    "    \n",
    "    transformed_image = transformed['image']\n",
    "    transformed_bbox = transformed['bboxes'][0]\n",
    "    \n",
    "    return transformed_image, transformed_bbox\n",
    "    \n",
    "def df_to_yolo(df, root_dir, transforms = None, num_gen=3, img_src_dir = None):\n",
    "    \n",
    "    img_path = root_dir + \"/\" + \"images\"\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "\n",
    "    lbl_path = root_dir + \"/\" + \"labels\"\n",
    "    if not os.path.exists(lbl_path):\n",
    "        os.makedirs(lbl_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the image name\n",
    "        image_name = row['path']\n",
    "\n",
    "        img_src_dir = row['img_dir']\n",
    "        \n",
    "        class_idx = row['type']\n",
    "\n",
    "        xmin = row['xmin']\n",
    "        ymin = row['ymin']\n",
    "        xmax = row['xmax']\n",
    "        ymax = row['ymax']\n",
    "\n",
    "        bbox = [xmin, ymin, xmax, ymax]\n",
    "        \n",
    "        if transforms is None:\n",
    "\n",
    "            shutil.copy(os.path.join(img_src_dir, image_name), os.path.join(img_path, image_name))\n",
    "            filename = os.path.splitext(image_name)[0]\n",
    "\n",
    "            # Open the image file\n",
    "            with Image.open(os.path.join(img_src_dir, image_name)) as img:\n",
    "            # Get the width and height\n",
    "                imgWidth, imgHeight = img.size\n",
    "\n",
    "            center_x = (xmin + xmax) / 2.0\n",
    "            center_y = (ymin + ymax) / 2.0\n",
    "    \n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "    \n",
    "            norm_center_x = center_x / imgWidth\n",
    "            norm_center_y = center_y / imgHeight\n",
    "            \n",
    "            norm_width = width / imgWidth\n",
    "            norm_height = height / imgHeight\n",
    "            \n",
    "            box_annotation = ' '.join([str(class_idx), str(norm_center_x), str(norm_center_y), str(norm_width), str(norm_height)])+'\\n'\n",
    "    \n",
    "            label_filename = lbl_path + '/' + filename + \".txt\"\n",
    "            anno_f = open(label_filename, 'w')\n",
    "            anno_f.writelines(box_annotation)\n",
    "            anno_f.close()\n",
    "\n",
    "            continue\n",
    "\n",
    "        original_image_path = os.path.join(img_src_dir, image_name)\n",
    "        img = cv2.imread(original_image_path)\n",
    "        imgHeight, imgWidth, _ = img.shape\n",
    "        \n",
    "        for i in range(num_gen):  # Apply transformations 5 times\n",
    "            transformed_image, transformed_bbox = apply_transformations(img, bbox, transforms)\n",
    "            \n",
    "            center_x = (transformed_bbox[0] + transformed_bbox[2]) / 2.0\n",
    "            center_y = (transformed_bbox[1] + transformed_bbox[3]) / 2.0\n",
    "\n",
    "            width = transformed_bbox[2] - transformed_bbox[0]\n",
    "            height = transformed_bbox[3] - transformed_bbox[1]\n",
    "            \n",
    "            norm_center_x = center_x / imgWidth\n",
    "            norm_center_y = center_y / imgHeight\n",
    "            \n",
    "            norm_width = width / imgWidth\n",
    "            norm_height = height / imgHeight\n",
    "            \n",
    "            box_annotation = ' '.join([str(class_idx), str(norm_center_x), str(norm_center_y), str(norm_width), str(norm_height)]) + '\\n'\n",
    "            \n",
    "            transformed_image_name = f\"{os.path.splitext(image_name)[0]}_transformed_{i}.jpg\"\n",
    "            cv2.imwrite(os.path.join(img_path, transformed_image_name), transformed_image)\n",
    "            \n",
    "            label_filename = os.path.join(lbl_path, f\"{os.path.splitext(transformed_image_name)[0]}.txt\")\n",
    "            with open(label_filename, 'w') as anno_f:\n",
    "                anno_f.writelines(box_annotation)\n",
    "\n",
    "    print(\"Done !\")\n",
    "\n",
    "\n",
    "def delete_dir_if_exists(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        try:\n",
    "            shutil.rmtree(dir_path)\n",
    "            print(f\"Directory '{dir_path}' deleted\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error deleting directory '{dir_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428afab2-bbe4-49a1-9bf1-83983c420bb7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/data/konrad/workspace\"\n",
    "DATA_FILE = ROOT_DIR + '/datasets/CompleteDatasetNormalFace/Face_annotations.csv'\n",
    "IMAGE_DIR = ROOT_DIR + \"/datasets/CompleteDatasetNormalFace\"\n",
    "\n",
    "face_df, labels, label2id, id2label = load_face_data(DATA_FILE, IMAGE_DIR)\n",
    "face_df[\"img_dir\"] = IMAGE_DIR\n",
    "face_df[\"type\"] = 0\n",
    "\n",
    "mix_df = pd.concat([face_df], ignore_index=True)\n",
    "\n",
    "filter_values = {\n",
    "    'calf': ['6842', '6436', '6864'],  # Specify the values you want to include\n",
    "}\n",
    "\n",
    "valid_df = mix_df[mix_df['calf'].isin(filter_values['calf'])]\n",
    "train_df = mix_df[~ mix_df['calf'].isin(filter_values['calf'])]\n",
    "\n",
    "IMAGE_DIR = ROOT_DIR + \"/datasets/calfs_face\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006080ae-51da-40c8-9395-fd724428d75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>fitness</th>\n",
       "      <th>save_dir</th>\n",
       "      <th>try</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826476</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.699150</td>\n",
       "      <td>0.459030</td>\n",
       "      <td>0.483042</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991248</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.903756</td>\n",
       "      <td>0.454722</td>\n",
       "      <td>0.499626</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.758097</td>\n",
       "      <td>0.699054</td>\n",
       "      <td>0.762188</td>\n",
       "      <td>0.424689</td>\n",
       "      <td>0.458439</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769589</td>\n",
       "      <td>0.891786</td>\n",
       "      <td>0.502220</td>\n",
       "      <td>0.541177</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.828900</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.685414</td>\n",
       "      <td>0.485180</td>\n",
       "      <td>0.505204</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.828499</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.640673</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.493998</td>\n",
       "      <td>/data/konrad/workspace/training_log/yolo_face24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    metrics/precision(B)  metrics/recall(B)  metrics/mAP50(B)  \\\n",
       "0               0.826476           0.555556          0.699150   \n",
       "1               0.991248           0.666667          0.903756   \n",
       "2               0.758097           0.699054          0.762188   \n",
       "3               0.828499           0.555556          0.640673   \n",
       "4               1.000000           0.769589          0.891786   \n",
       "5               0.828900           0.555556          0.685414   \n",
       "6               0.828499           0.555556          0.640673   \n",
       "7               0.828499           0.555556          0.640673   \n",
       "8               0.828499           0.555556          0.640673   \n",
       "9               0.828499           0.555556          0.640673   \n",
       "10              0.828499           0.555556          0.640673   \n",
       "11              0.828499           0.555556          0.640673   \n",
       "12              0.828499           0.555556          0.640673   \n",
       "13              0.828499           0.555556          0.640673   \n",
       "\n",
       "    metrics/mAP50-95(B)   fitness  \\\n",
       "0              0.459030  0.483042   \n",
       "1              0.454722  0.499626   \n",
       "2              0.424689  0.458439   \n",
       "3              0.477700  0.493998   \n",
       "4              0.502220  0.541177   \n",
       "5              0.485180  0.505204   \n",
       "6              0.477700  0.493998   \n",
       "7              0.477700  0.493998   \n",
       "8              0.477700  0.493998   \n",
       "9              0.477700  0.493998   \n",
       "10             0.477700  0.493998   \n",
       "11             0.477700  0.493998   \n",
       "12             0.477700  0.493998   \n",
       "13             0.477700  0.493998   \n",
       "\n",
       "                                           save_dir  try  \n",
       "0   /data/konrad/workspace/training_log/yolo_face11    0  \n",
       "1   /data/konrad/workspace/training_log/yolo_face12    0  \n",
       "2   /data/konrad/workspace/training_log/yolo_face13    0  \n",
       "3   /data/konrad/workspace/training_log/yolo_face14    1  \n",
       "4   /data/konrad/workspace/training_log/yolo_face15    1  \n",
       "5   /data/konrad/workspace/training_log/yolo_face16    1  \n",
       "6   /data/konrad/workspace/training_log/yolo_face17    2  \n",
       "7   /data/konrad/workspace/training_log/yolo_face18    3  \n",
       "8   /data/konrad/workspace/training_log/yolo_face19    4  \n",
       "9   /data/konrad/workspace/training_log/yolo_face20    5  \n",
       "10  /data/konrad/workspace/training_log/yolo_face21    6  \n",
       "11  /data/konrad/workspace/training_log/yolo_face22    7  \n",
       "12  /data/konrad/workspace/training_log/yolo_face23    8  \n",
       "13  /data/konrad/workspace/training_log/yolo_face24    9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_exp = 10\n",
    "max_perfo = 0 \n",
    "records = []\n",
    "base_epoch = 30\n",
    "num_gen = 5\n",
    "\n",
    "for _ in range(num_exp):\n",
    "\n",
    "    delete_dir_if_exists(IMAGE_DIR)\n",
    "\n",
    "    transforms = A.Compose([\n",
    "        A.Rotate(limit=(10, 20), p=.7),\n",
    "        A.OneOf([\n",
    "            A.GaussianBlur(blur_limit=(3,9), p=.7),\n",
    "            A.MedianBlur(blur_limit=7, p=.7),\n",
    "        ], p=.6),\n",
    "        A.Sharpen(p=.7),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))\n",
    "    \n",
    "    df_to_yolo(train_df, IMAGE_DIR + '/train', img_src_dir = IMAGE_DIR, transforms = transforms, num_gen=num_gen)\n",
    "    df_to_yolo(valid_df, IMAGE_DIR + '/test', img_src_dir = IMAGE_DIR)\n",
    "\n",
    "    # Load a model\n",
    "    model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "    \n",
    "    results = model.train(data=\"yolo-face.yml\", epochs=base_epoch, project=ROOT_DIR + \"/training_log\", name=\"yolo_face\", cfg=\"config.yml\")\n",
    "    model.export()\n",
    "    clear_output()\n",
    "    \n",
    "    metrics = results.results_dict\n",
    "    metrics[\"save_dir\"] = str(results.save_dir)\n",
    "    metrics[\"try\"] = _\n",
    "    records.append(metrics)\n",
    "    \n",
    "    last_best_perfo = 0\n",
    "    epochs = base_epoch + 10\n",
    "    \n",
    "    if max_perfo < results.results_dict[\"metrics/mAP50-95(B)\"]:\n",
    "        \n",
    "        max_perfo = results.results_dict[\"metrics/mAP50-95(B)\"]\n",
    "        for __ in range(10):        \n",
    "            # Load a model\n",
    "            model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "            \n",
    "            last_results = model.train(data=\"yolo-face.yml\", epochs=epochs, project=ROOT_DIR + \"/training_log\", name=\"yolo_face\", cfg=\"config.yml\")\n",
    "            model.export()\n",
    "            clear_output()\n",
    "    \n",
    "            metrics = last_results.results_dict\n",
    "            metrics[\"save_dir\"] = str(last_results.save_dir)\n",
    "            metrics[\"try\"] = _\n",
    "            records.append(metrics)\n",
    "            \n",
    "            if last_best_perfo > last_results.results_dict[\"metrics/mAP50-95(B)\"]:\n",
    "                break\n",
    "    \n",
    "            epochs+=10\n",
    "            last_best_perfo = last_results.results_dict[\"metrics/mAP50-95(B)\"]\n",
    "\n",
    "\n",
    "        max_perfo = max(max_perfo, last_best_perfo)\n",
    "        \n",
    "    \n",
    "records = pd.DataFrame(records)\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c44195e-5516-45cb-af31-0271d95d6bd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/data/konrad/workspace/datasets/calfs_face' deleted\n",
      "Done !\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Rotate(limit=(10, 20), p=.7),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3,9), p=.7),\n",
    "        A.MedianBlur(blur_limit=7, p=.7),\n",
    "    ], p=.6),\n",
    "    A.Sharpen(p=.7),\n",
    "    # A.OneOf([\n",
    "    #     A.ChannelShuffle(p=.7),\n",
    "    #     A.RGBShift(p=.7),\n",
    "    #     A.InvertImg(p=.5),\n",
    "    #     A.ToGray(p=.8),\n",
    "    # ], p=.6),\n",
    "    # A.OneOf([\n",
    "    #     A.Sharpen(p=.7),\n",
    "    #     A.ColorJitter(brightness=0.2, contrast=0.5, saturation=0.5, hue=0.2, p=.7)\n",
    "    # ], p=.6)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))\n",
    "num_gen = 5\n",
    "\n",
    "delete_dir_if_exists(IMAGE_DIR)\n",
    "df_to_yolo(train_df, IMAGE_DIR + '/train', img_src_dir = IMAGE_DIR, transforms = transforms, num_gen=num_gen)\n",
    "df_to_yolo(valid_df, IMAGE_DIR + '/test', img_src_dir = IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765e1ba2-8f9f-4a8a-ac57-a50af706a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.74 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.58 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=yolo-face.yml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/data/konrad/workspace/training_log, name=yolo_face25, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.8, bgr=0.0, mosaic=0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=1, cfg=config.yml, tracker=botsort.yaml, save_dir=/data/konrad/workspace/training_log/yolo_face25\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /data/konrad/workspace/training_log/yolo_face25', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/konrad/workspace/datasets/calfs_face/train/labels... 890 images, 0 backgrounds, 0 corrupt: 100%|██\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data/konrad/workspace/datasets/calfs_face/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/konrad/workspace/datasets/calfs_face/test/labels... 9 images, 0 backgrounds, 0 corrupt: 100%|███████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/konrad/workspace/datasets/calfs_face/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /data/konrad/workspace/training_log/yolo_face25/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/data/konrad/workspace/training_log/yolo_face25\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      2.23G      1.534      2.678      1.468         10        640: 100%|██████████| 56/56 [00:03<00:00, 16.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.746      0.444      0.438      0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      2.26G      1.164      1.489      1.112         10        640: 100%|██████████| 56/56 [00:03<00:00, 17.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.986      0.556      0.696      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      2.25G     0.9343      1.104     0.9953         10        640: 100%|██████████| 56/56 [00:03<00:00, 17.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.823      0.556      0.516      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      2.25G     0.8202     0.8718     0.9378         10        640: 100%|██████████| 56/56 [00:03<00:00, 18.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.992      0.667      0.808      0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      2.25G     0.6811     0.6983     0.8823         10        640: 100%|██████████| 56/56 [00:02<00:00, 18.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9          1      0.666      0.811       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_face25/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_face25/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /data/konrad/workspace/training_log/yolo_face25/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.58 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9          1      0.666      0.811       0.48\n",
      "Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_face25\u001b[0m\n",
      "Ultralytics YOLOv8.2.58 🚀 Python-3.10.12 torch-2.3.1+cu121 CPU (AMD Ryzen Threadripper PRO 5975WX 32-Cores)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/data/konrad/workspace/training_log/yolo_face25/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1+cu121...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 0.8s, saved as '/data/konrad/workspace/training_log/yolo_face25/weights/best.torchscript' (11.9 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_face25/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/data/konrad/workspace/training_log/yolo_face25/weights/best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=/data/konrad/workspace/training_log/yolo_face25/weights/best.torchscript imgsz=640 data=yolo-face.yml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/konrad/workspace/training_log/yolo_face25/weights/best.torchscript'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model.train(data=\"yolo-face.yml\", epochs=5, project=ROOT_DIR + \"/training_log\", name=\"yolo_face\", cfg=\"config.yml\")\n",
    "\n",
    "model.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main_env)",
   "language": "python",
   "name": "x_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

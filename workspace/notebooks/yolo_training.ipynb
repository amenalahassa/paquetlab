{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebba3a0d-7eef-4848-a00b-9e06d5c80aa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Local dep\n",
    "project_dir = '/data/konrad/workspace'\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from helpers.datasets import CalfCenterFaceDataset\n",
    "from helpers.helpers import get_indices, uniform_sample_with_values, load_face_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf191360-2536-4052-a1ed-b2a26099c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox_gallery(image_df, n_cols=5):\n",
    "    n_images = image_df.shape[0]\n",
    "    n_rows = n_images // n_cols + int(n_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(20, n_rows * 4))\n",
    "    for i, row in image_df.iterrows():\n",
    "        img = Image.open(row[\"path\"])\n",
    "        # plt.subplot(n_rows, n_cols, i + 1)\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        # ax = plt.gca()\n",
    "        score = row[\"conf\"]\n",
    "        box_x = row[\"box_x\"]\n",
    "        box_y = row[\"box_y\"]\n",
    "        box_width = row[\"box_width\"]\n",
    "        box_height = row[\"box_height\"]\n",
    "        box_x = box_x - (box_width / 2)\n",
    "        box_y = box_y - (box_height / 2)\n",
    "        rect = plt.Rectangle((box_x, box_y), box_width, box_height, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(box_x, box_y - 10, f' {score:.2f}', color='red', fontsize=12, backgroundcolor='white')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def df_to_yolo(df, root_dir, img_src_dir = None):\n",
    "    \n",
    "    img_path = root_dir + \"/\" + \"images\"\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "\n",
    "    lbl_path = root_dir + \"/\" + \"labels\"\n",
    "    if not os.path.exists(lbl_path):\n",
    "        os.makedirs(lbl_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the image name\n",
    "        image_name = row['path']\n",
    "\n",
    "        img_src_dir = row['img_dir']\n",
    "        shutil.copy(os.path.join(img_src_dir, image_name), os.path.join(img_path, image_name))\n",
    "        filename = os.path.splitext(image_name)[0]\n",
    "\n",
    "        # Open the image file\n",
    "        with Image.open(os.path.join(img_src_dir, image_name)) as img:\n",
    "            # Get the width and height\n",
    "            imgWidth, imgHeight = img.size\n",
    "\n",
    "        class_idx = row['type']\n",
    "        # class_idx = 0\n",
    "\n",
    "        xmin = row['xmin']\n",
    "        ymin = row['ymin']\n",
    "        xmax = row['xmax']\n",
    "        ymax = row['ymax']\n",
    "\n",
    "        center_x = (xmin + xmax) / 2.0\n",
    "        center_y = (ymin + ymax) / 2.0\n",
    "\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        \n",
    "        # image = cv2.imread(os.path.join(img_src_dir, image_name))\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "        # plt.figure(figsize=(10, 10))\n",
    "        # plt.imshow(image)\n",
    "        # ax = plt.gca()\n",
    "        \n",
    "        # rect = plt.Rectangle((xmin, ymin), width, height, edgecolor='r', facecolor='none')\n",
    "        # ax.add_patch(rect)\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "        # print(center_x == (xmin + (width / 2)), center_x, xmin + (width / 2))\n",
    "        # break\n",
    "        \n",
    "        norm_center_x = center_x / imgWidth\n",
    "        norm_center_y = center_y / imgHeight\n",
    "        \n",
    "        norm_width = width / imgWidth\n",
    "        norm_height = height / imgHeight\n",
    "        \n",
    "        box_annotation = ' '.join([str(class_idx), str(norm_center_x), str(norm_center_y), str(norm_width), str(norm_height)])+'\\n'\n",
    "\n",
    "        label_filename = lbl_path + '/' + filename + \".txt\"\n",
    "        anno_f = open(label_filename, 'w')\n",
    "        anno_f.writelines(box_annotation)\n",
    "        anno_f.close()\n",
    "\n",
    "    print(\"Done !\")\n",
    "\n",
    "\n",
    "def delete_dir_if_exists(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        try:\n",
    "            shutil.rmtree(dir_path)\n",
    "            print(f\"Directory '{dir_path}' deleted\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error deleting directory '{dir_path}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7ac966-b7a3-4e50-9610-ab4796d2f651",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/data/konrad/workspace/datasets/calfs_face' deleted\n",
      "Done !\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = \"/data/konrad/workspace\"\n",
    "DATA_FILE = ROOT_DIR + '/datasets/CompleteDatasetNormalFace/Face_annotations.csv'\n",
    "IMAGE_DIR = ROOT_DIR + \"/datasets/CompleteDatasetNormalFace\"\n",
    "\n",
    "face_df, labels, label2id, id2label = load_face_data(DATA_FILE, IMAGE_DIR)\n",
    "face_df[\"img_dir\"] = IMAGE_DIR\n",
    "face_df[\"type\"] = 0\n",
    "\n",
    "# DATA_FILE = '/data/konrad/datasets/CompleteDatasetNormalProfilDroit/Profil_droit_annotations.csv'\n",
    "# IMAGE_DIR = \"/data/konrad/datasets/CompleteDatasetNormalProfilDroit\"\n",
    "\n",
    "# rigth_df, _, _, _ = load_face_data(DATA_FILE, IMAGE_DIR, extract_name=False)\n",
    "# rigth_df[\"img_dir\"] = IMAGE_DIR\n",
    "# rigth_df[\"type\"] = 1\n",
    "\n",
    "\n",
    "# DATA_FILE = '/data/konrad/datasets/CompleteDatasetNormalProfilGauche/Profil_gauche_annotations.csv'\n",
    "# IMAGE_DIR = \"/data/konrad/datasets/CompleteDatasetNormalProfilGauche\"\n",
    "\n",
    "# left_df, _, _, _ = load_face_data(DATA_FILE, IMAGE_DIR, extract_name=False)\n",
    "# left_df[\"img_dir\"] = IMAGE_DIR\n",
    "# left_df[\"type\"] = 2\n",
    "\n",
    "mix_df = pd.concat([face_df], ignore_index=True)\n",
    "# mix_df = pd.concat([face_df, rigth_df, left_df], ignore_index=True)\n",
    "# mix_df['type'] = 0 Only for any detector\n",
    "\n",
    "filter_values = {\n",
    "    'calf': ['6842', '6436', '6864'],  # Specify the values you want to include\n",
    "}\n",
    "\n",
    "valid_df = mix_df[mix_df['calf'].isin(filter_values['calf'])]\n",
    "train_df = mix_df[~ mix_df['calf'].isin(filter_values['calf'])]\n",
    "\n",
    "IMAGE_DIR = ROOT_DIR + \"/datasets/calfs_face\"\n",
    "delete_dir_if_exists(IMAGE_DIR)\n",
    "df_to_yolo(train_df, IMAGE_DIR + '/train', IMAGE_DIR)\n",
    "df_to_yolo(valid_df, IMAGE_DIR + '/test', IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765e1ba2-8f9f-4a8a-ac57-a50af706a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.64 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=yolo-face.yml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/data/konrad/workspace/training_log, name=yolo_face, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.8, hsv_s=0, hsv_v=0, degrees=0, translate=0.5, scale=0.5, shear=0.5, perspective=0.0, flipud=0.0, fliplr=0.8, bgr=0.0, mosaic=1, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=config.yml, tracker=botsort.yaml, save_dir=/data/konrad/workspace/training_log/yolo_face\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /data/konrad/workspace/training_log/yolo_face', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/konrad/workspace/datasets/calfs_face/train/labels... 178 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 178/178 [00:00<00:00, 2956.14it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data/konrad/workspace/datasets/calfs_face/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/konrad/workspace/datasets/calfs_face/test/labels... 9 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 2797.03it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/konrad/workspace/datasets/calfs_face/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /data/konrad/workspace/training_log/yolo_face/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/data/konrad/workspace/training_log/yolo_face\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      2.19G      1.766       5.75      1.634          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9    0.00259      0.778      0.154     0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.13G      1.488      3.153      1.391          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9    0.00259      0.778      0.272     0.0825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      2.23G      1.239      2.602       1.21          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9    0.00259      0.778      0.382       0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      2.13G      1.264      2.463       1.26          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 35.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9     0.0038      0.667      0.413      0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.14G      1.169      2.151      1.146          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.771       0.38      0.494      0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.14G      1.277      2.265      1.178          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 22.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.815      0.333      0.431       0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.14G      1.146      1.995      1.136          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 38.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9       0.71      0.545      0.577      0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.14G      1.177      2.057      1.219          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 21.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 37.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.838      0.578      0.652      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      2.14G      1.086      1.769      1.119          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 19.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.968      0.667      0.797      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.14G       1.01      1.667      1.081          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 19.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 31.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.747      0.658      0.837      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_face/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_face/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /data/konrad/workspace/training_log/yolo_face/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          9          9      0.968      0.667      0.797      0.568\n",
      "Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_face\u001b[0m\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CPU (AMD Ryzen Threadripper PRO 5975WX 32-Cores)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/data/konrad/workspace/training_log/yolo_face/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1+cu121...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 0.8s, saved as '/data/konrad/workspace/training_log/yolo_face/weights/best.torchscript' (11.9 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_face/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/data/konrad/workspace/training_log/yolo_face/weights/best.torchscript imgsz=640  \n",
      "Validate:        yolo val task=detect model=/data/konrad/workspace/training_log/yolo_face/weights/best.torchscript imgsz=640 data=yolo-face.yml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/konrad/workspace/training_log/yolo_face/weights/best.torchscript'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model.train(data=\"yolo-face.yml\", epochs=10, project=ROOT_DIR + \"/training_log\", name=\"yolo_face\", cfg=\"config.yml\")\n",
    "\n",
    "model.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main_env)",
   "language": "python",
   "name": "x_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76852df3-783e-4504-9863-51c46adbe624",
   "metadata": {},
   "source": [
    "# Classification d'image vue de face de veaux avec Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a17a0e-13f5-4185-8ef8-dfdacaef5a16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import des dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c2159c-e743-4622-a4b8-3ce6187d34ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 13:55:33.276719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-27 13:55:33.287113: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-27 13:55:33.290293: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-27 13:55:33.299170: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 13:55:33.990973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models.segmentation as segmentation\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from PIL import Image as PilImage\n",
    "from omnixai.data.image import Image\n",
    "from omnixai.explainers.vision import LimeImage, VisionExplainer\n",
    "from omnixai.preprocessing.image import Resize\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from IPython.display import clear_output\n",
    "import timm\n",
    "\n",
    "# Local dep\n",
    "project_dir = '/data/konrad/workspace'\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from helpers.helpers import get_indices, load_face_data, load_local_model\n",
    "from helpers.datasets import CalfCenterFaceDataset\n",
    "from helpers.interp import GradCam, generate_cam, display_predicted_cam\n",
    "from helpers.trainers import train_model, validate_model, plot_metrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89cf51-b6ad-40c9-a94a-3110e666b664",
   "metadata": {},
   "source": [
    "## Classes et utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a525ca-4d18-46ea-8dab-68f53283fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes, name, from_pretrained=True):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.name = name\n",
    "        self.unet = segmentation.deeplabv3_resnet50(pretrained=from_pretrained)  # Load the U-Net backbone\n",
    "\n",
    "        # Remove the last segmentation layer\n",
    "        self.unet.classifier = nn.Identity()\n",
    "\n",
    "        self.conv_head = nn.Conv2d(2048, num_classes, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Global average pooling\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.unet(x)['out']\n",
    "        features = self.conv_head(features)\n",
    "        output = self.classifier_head(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8f0d1-574f-419b-bd50-65c65517aa13",
   "metadata": {},
   "source": [
    "## Entrainement du modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9062e11-0054-4664-bd96-03b762db03f8",
   "metadata": {},
   "source": [
    "### Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9d6b87-5850-42a8-b2d4-069cc7d8173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_indices, test_indices, valid_indices = get_indices(len(df))\n",
    "ROOT_DIR = \"/data/konrad/workspace\"\n",
    "DATA_FILE = ROOT_DIR + \"/csv_files/CompleteDatasetNormalFace/Face_annotations.csv\"\n",
    "IMAGE_DIR = ROOT_DIR + \"/csv_files/CompleteDatasetNormalFace\"\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "# dataset_type = \"splt\"\n",
    "dataset_type = \"loco\"\n",
    "\n",
    "# df, labels, label2id, id2label = load_face_data(DATA_FILE, IMAGE_DIR)\n",
    "# root_dir = ROOT_DIR + f\"/datasets/mixed_{frame}s_b{step}s\"\n",
    "# root_dir = f\"/data/data_calves/konrad/mixed_{frame}s_b{step}s\"\n",
    "\n",
    "train_df = pd.read_csv(ROOT_DIR + f'/csv_files/mixed_10s_b0s_y7_1/{dataset_type}_train_image_extracted_metadata.csv', index_col=False)\n",
    "valid_df = pd.read_csv(ROOT_DIR + f'/csv_files/mixed_10s_b0s_y7_1/{dataset_type}_test_image_extracted_metadata.csv', index_col=False)\n",
    "test_df = pd.read_csv(ROOT_DIR + f'/csv_files/mixed_10s_b0s_y7_1/{dataset_type}_val_image_extracted_metadata.csv', index_col=False)\n",
    "\n",
    "label_col = \"bilabel\"\n",
    "# label_col = \"label\"\n",
    "# train_df = train_df[~ (train_df[label_col] == \"Diarrhé, Pneumonie\")]\n",
    "# valid_df = valid_df[~ (valid_df[label_col] == \"Diarrhé, Pneumonie\")]\n",
    "# test_df = test_df[~ (test_df[label_col] == \"Diarrhé, Pneumonie\")]\n",
    "\n",
    "labels = train_df[label_col].unique()\n",
    "label2id = {l:i for i, l in enumerate(labels)}\n",
    "id2label = {i:l for i, l in enumerate(labels)}\n",
    "\n",
    "# num_labels = len(labels)\n",
    "num_labels = 1\n",
    "train_df['target'] = train_df.apply(lambda row: label2id[row[label_col]], axis=1)\n",
    "test_df['target'] = test_df.apply(lambda row: label2id[row[label_col]], axis=1)\n",
    "valid_df['target'] = valid_df.apply(lambda row: label2id[row[label_col]], axis=1)\n",
    "test_df = test_df.sample(frac=.10).reset_index(drop=True)\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    v2.Resize(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.AutoAugment(v2.AutoAugmentPolicy.IMAGENET),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CalfCenterFaceDataset(train_df, transform=train_transform)\n",
    "test_dataset = CalfCenterFaceDataset(test_df, transform=test_transform)\n",
    "valid_dataset = CalfCenterFaceDataset(valid_df, transform=test_transform)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=ImbalancedDatasetSampler(train_dataset))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size * 2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size * 2, shuffle=False)\n",
    "\n",
    "# dl = valid_loader.dataset.data_frame\n",
    "# class_counts = dl['label'].value_counts()\n",
    "\n",
    "# # Plot the distribution\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# class_counts.plot(kind='bar')\n",
    "# plt.title('Distribution of Classes in Validation set')\n",
    "# plt.xlabel('Class')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dce62f-83cc-4bc7-a396-8ef996eb1d41",
   "metadata": {},
   "source": [
    "### Entrainement et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d43b6e-c6ba-414e-bc32-72f5f273be88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/konrad/x_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/konrad/x_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 213 and validating on 694 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 107/107 [00:33<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15]\n",
      "Train Loss: 0.0067, Accuracy: 0.5211, Recall: 0.7553, F1 Score: 0.5820\n",
      "Validating on 694 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 174/174 [01:05<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3141, Recall: 0.9070, F1 Score: 0.3959, Bal Acc Score: 0.5129\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████████████████████████████▎                                           | 50/107 [00:14<00:16,  3.37it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     average \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m ROOT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/training_log\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m metrics_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m clear_output()\n\u001b[1;32m     21\u001b[0m plot_metrics(metrics_scores)\n",
      "File \u001b[0;32m~/workspace/helpers/trainers.py:51\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, labels_name, train_loader, valid_loader, scheduler, patience, optimizer, output_dir, num_epochs, average)\u001b[0m\n\u001b[1;32m     48\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 51\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     54\u001b[0m all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = f\"efficientnet_{dataset_type}_{label_col}_{batch_size}\"\n",
    "model = Classifier(num_classes=num_labels, name=model_name, from_pretrained=True)  # Adjust num_classes according to your dataset\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "lr = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "epochs = 15\n",
    "patience = 3\n",
    "\n",
    "if num_labels == 1:\n",
    "    average = \"binary\"\n",
    "else:\n",
    "    average = \"weighted\"\n",
    "\n",
    "output_dir = ROOT_DIR + \"/training_log\"\n",
    "metrics_scores = train_model(model, labels, train_loader, test_loader, scheduler, patience, optimizer, output_dir, num_epochs = epochs, average=average)\n",
    "clear_output()\n",
    "plot_metrics(metrics_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ccb7e-015c-41e6-879b-e03e9559779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{output_dir}/models/best_{model.name}_model.pth'))\n",
    "validate_model(model, valid_loader, labels, average=average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e77857-b54b-4fa6-b412-d0e1475c1480",
   "metadata": {},
   "source": [
    "## Interpretation with Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3aa30-0475-4440-a377-5cb211297752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Classifier(num_classes=len(labels), name=model_name, from_pretrained=False)  # Adjust num_classes according to your dataset\n",
    "# model.load_state_dict(torch.load(f'{output_dir}/models/best_{model.name}_model.pth'))\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b46c98-77a2-4e3c-ab1f-f2dd7b8ecd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = valid_loader.dataset.data_frame.copy(deep=True)\n",
    "# test_df.reset_index(drop=True, inplace=True)\n",
    "# test_images = [Resize((256, 256)).transform(Image(PilImage.open(p[\"path\"]).convert('RGB'))).to_numpy() for p in test_df.to_dict('records')]\n",
    "# img = Image( data=np.concatenate(test_images), batched=True)\n",
    "\n",
    "# # The preprocessing function\n",
    "# transform = v2.Compose([\n",
    "#     v2.Resize(256),\n",
    "#     v2.CenterCrop(224),\n",
    "#     v2.ToImage(),\n",
    "#     v2.ToDtype(torch.float32, scale=True),\n",
    "#     v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "# preprocess = lambda ims: torch.stack([transform(im.to_pil()) for im in ims]).to(device)\n",
    "# postprocess = lambda logits: torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "# target_head = model.conv_head\n",
    "# target_layer = model.conv_head\n",
    "# explainer = VisionExplainer(\n",
    "#     explainers=[\n",
    "#        \"gradcam\",\n",
    "#         \"lime\", \n",
    "#         # \"ig\",\n",
    "#         # \"ce\",\n",
    "#         # \"scorecam\",\n",
    "#         # \"smoothgrad\", \n",
    "#         \"guidedbp\", \n",
    "#         \"layercam\"\n",
    "#     ],\n",
    "#     mode=\"classification\",\n",
    "#     model=model,\n",
    "#     preprocess=preprocess,\n",
    "#     postprocess=postprocess,\n",
    "#     params={\n",
    "#         \"gradcam\": {\"target_layer\": target_head},\n",
    "#         # \"ce\": {\"binary_search_steps\": 2, \"num_iterations\": 100},\n",
    "#         # \"scorecam\": {\"target_layer\": target_head},\n",
    "#         \"layercam\": {\"target_layer\": target_layer},\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # Generate explanations\n",
    "# local_explanations = explainer.explain(img)\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e443b7-e101-4f66-84c6-68ec11d89723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_per_class = {l:test_df[test_df[\"label\"] == l] for l in labels}\n",
    "# class_id = 0\n",
    "# l, f_df  = list(df_per_class.items())[class_id]\n",
    "# print(f\"Class label: {l}:\\n\\t\")\n",
    "\n",
    "# for row_id in f_df.index.values:\n",
    "\n",
    "#     print(f\"Interpretation pour image {row_id}: \\n\")\n",
    "#     for name, explanations in local_explanations.items():\n",
    "#         print(f\"{name}:\")\n",
    "#         explanations.ipython_plot(row_id, class_names=labels)\n",
    "\n",
    "\n",
    "# print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521b487-4bef-4ef5-9b0f-232578903e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_per_class = {l:test_df[test_df[\"label\"] == l] for l in labels}\n",
    "# class_id = 1\n",
    "# l, f_df  = list(df_per_class.items())[class_id]\n",
    "# print(f\"Class label: {l}:\\n\\t\")\n",
    "\n",
    "# for row_id in f_df.index.values:\n",
    "\n",
    "#     print(f\"Interpretation pour image {row_id}: \\n\")\n",
    "#     for name, explanations in local_explanations.items():\n",
    "#         print(f\"{name}:\")\n",
    "#         explanations.ipython_plot(row_id, class_names=labels)\n",
    "\n",
    "\n",
    "# print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49509184-b624-4a56-8481-c551ea17bf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_per_class = {l:test_df[test_df[\"label\"] == l] for l in labels}\n",
    "# class_id = 2\n",
    "# l, f_df  = list(df_per_class.items())[class_id]\n",
    "# print(f\"Class label: {l}:\\n\\t\")\n",
    "\n",
    "# for row_id in f_df.index.values:\n",
    "\n",
    "#     print(f\"Interpretation pour image {row_id}: \\n\")\n",
    "#     for name, explanations in local_explanations.items():\n",
    "#         print(f\"{name}:\")\n",
    "#         explanations.ipython_plot(row_id, class_names=labels)\n",
    "\n",
    "\n",
    "# print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

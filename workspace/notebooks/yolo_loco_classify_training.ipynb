{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebba3a0d-7eef-4848-a00b-9e06d5c80aa3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.12). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import yaml\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# Local dep\n",
    "project_dir = '/data/konrad/workspace'\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from helpers.datasets import CalfCenterFaceDataset\n",
    "from helpers.helpers import get_indices, uniform_sample_with_values, load_face_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf191360-2536-4052-a1ed-b2a26099c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox_gallery(image_df, n_cols=5):\n",
    "    n_images = image_df.shape[0]\n",
    "    n_rows = n_images // n_cols + int(n_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(20, n_rows * 4))\n",
    "    for i, row in image_df.iterrows():\n",
    "        img = Image.open(row[\"path\"])\n",
    "        # plt.subplot(n_rows, n_cols, i + 1)\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        # ax = plt.gca()\n",
    "        score = row[\"conf\"]\n",
    "        box_x = row[\"box_x\"]\n",
    "        box_y = row[\"box_y\"]\n",
    "        box_width = row[\"box_width\"]\n",
    "        box_height = row[\"box_height\"]\n",
    "        box_x = box_x - (box_width / 2)\n",
    "        box_y = box_y - (box_height / 2)\n",
    "        rect = plt.Rectangle((box_x, box_y), box_width, box_height, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(box_x, box_y - 10, f' {score:.2f}', color='red', fontsize=12, backgroundcolor='white')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def apply_transformations(image, bbox, transforms, label_id):\n",
    "    transformed = transforms(image=image, bboxes=[bbox], category_ids=[label_id])\n",
    "    \n",
    "    transformed_image = transformed['image']\n",
    "    transformed_bbox = transformed['bboxes'][0]\n",
    "    \n",
    "    return transformed_image, transformed_bbox\n",
    "    \n",
    "def df_to_yolo(df, root_dir, label_col = \"label\", transforms = None, num_gen=3):\n",
    "    \n",
    "    img_path = root_dir + \"/\"\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the image name\n",
    "        image_label = row[label_col]\n",
    "        \n",
    "        lbl_path = img_path + \"/\" + image_label\n",
    "        if not os.path.exists(lbl_path):\n",
    "            os.makedirs(lbl_path)\n",
    "        \n",
    "        image_name = row['image']\n",
    "\n",
    "        img_src_dir = row['path']\n",
    "        \n",
    "        class_idx = row['target']\n",
    "\n",
    "        xmin = row['x_min']\n",
    "        ymin = row['y_min']\n",
    "        xmax = row['x_max']\n",
    "        ymax = row['y_max']\n",
    "\n",
    "        bbox = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "        if transforms is None:\n",
    "\n",
    "            filename = os.path.splitext(image_name)[0]\n",
    "\n",
    "            # Open the image file\n",
    "            with Image.open(os.path.join(img_src_dir)) as img:\n",
    "            # Get the width and height\n",
    "                img_pil = img.crop((xmin, ymin, xmax, ymax))\n",
    "                img_pil.save(os.path.join(lbl_path, image_name))\n",
    "\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_src_dir)\n",
    "        \n",
    "        for i in range(num_gen):  # Apply transformations 5 times\n",
    "            transformed_image, transformed_bbox = apply_transformations(img, bbox, transforms, class_idx)\n",
    "            transformed_image_name = f\"{os.path.splitext(image_name)[0]}_transformed_{i}.jpg\"\n",
    "            \n",
    "            xmin, ymin, xmax, ymax = transformed_bbox\n",
    "            img_rgb = cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB)\n",
    "            img_pil = Image.fromarray(img_rgb).crop((xmin, ymin, xmax, ymax))\n",
    "            img_pil.save(os.path.join(lbl_path, transformed_image_name))\n",
    "\n",
    "    print(\"Done !\")\n",
    "\n",
    "\n",
    "def delete_dir_if_exists(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        try:\n",
    "            shutil.rmtree(dir_path)\n",
    "            print(f\"Directory '{dir_path}' deleted\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error deleting directory '{dir_path}': {e}\")\n",
    "\n",
    "def set_yml(file_name, data_path, id2label, train_dir = \"train\", test_dir = \"test\", val_dir = \"val\"):\n",
    "    \n",
    "    # Create the dictionary structure for YAML\n",
    "    yolo_detect_config = {\n",
    "        'path': data_path,\n",
    "        'train': train_dir,\n",
    "        'test': test_dir,\n",
    "        'val': val_dir,\n",
    "        'names': id2label\n",
    "    }\n",
    "    \n",
    "    # Define the output file path\n",
    "    yml_file_path = os.path.join(data_path, f\"{file_name}.yml\")\n",
    "    \n",
    "    # Write the YAML file\n",
    "    with open(yml_file_path, 'w') as yml_file:\n",
    "        yaml.dump(yolo_detect_config, yml_file, default_flow_style=False)\n",
    "        \n",
    "    print(\"Yml file set !\")\n",
    "    return yml_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428afab2-bbe4-49a1-9bf1-83983c420bb7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/data/konrad/workspace\"\n",
    "\n",
    "dataset_type = \"loco\"\n",
    "label_col = \"label\"\n",
    "\n",
    "num_labels = 3 if label_col == \"label\" else 1\n",
    "train_df = pd.read_csv(ROOT_DIR + f'/csv_files/mixed_10s_b0s_y7_1/{dataset_type}_train_image_extracted_metadata.csv', index_col=False)\n",
    "valid_df = pd.read_csv(ROOT_DIR + f'/csv_files/mixed_10s_b0s_y7_1/{dataset_type}_test_image_extracted_metadata.csv', index_col=False)\n",
    "test_df = pd.read_csv(ROOT_DIR + f'/csv_files/mixed_10s_b0s_y7_1/{dataset_type}_val_image_extracted_metadata.csv', index_col=False)\n",
    "labels = train_df[label_col].unique()\n",
    "label2id = {l:i for i, l in enumerate(labels)}\n",
    "id2label = {i:l for i, l in enumerate(labels)}\n",
    "train_df['target'] = train_df.apply(lambda row: label2id[row[label_col]], axis=1)\n",
    "test_df['target'] = test_df.apply(lambda row: label2id[row[label_col]], axis=1)\n",
    "valid_df['target'] = valid_df.apply(lambda row: label2id[row[label_col]], axis=1)\n",
    "test_df = test_df.sample(frac=.10).reset_index(drop=True)\n",
    "\n",
    "IMAGE_DIR = ROOT_DIR + f\"/datasets/yolo_classify_{dataset_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c08d54-a0e0-45fa-9c84-17e69da38a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n",
      "Done !\n",
      "Done !\n",
      "New https://pypi.org/project/ultralytics/8.2.84 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=/data/konrad/workspace/datasets/yolo_classify_loco, epochs=10, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=/data/konrad/workspace/training_log, name=yolo_classifier7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.8, bgr=0.0, mosaic=0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=1, cfg=config.yml, tracker=botsort.yaml, save_dir=/data/konrad/workspace/training_log/yolo_classifier7\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 1065 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 283 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 694 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    989443  ultralytics.nn.modules.head.Classify         [768, 3]                      \n",
      "YOLOv8m-cls summary: 141 layers, 15,776,179 parameters, 15,776,179 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /data/konrad/workspace/training_log/yolo_classifier7', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/train... 1065 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/val... 283 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 283/283 \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier7\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      1.14G      1.055          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00, 27.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 41.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.371          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      1.27G     0.6844          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 40.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 121.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.385          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      1.27G     0.2159          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 173.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.396          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      1.27G    0.08825          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 49.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 78.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.371          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      1.25G    0.07003          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 92.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.353          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      1.28G    0.05943          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 71.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.385          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      1.15G    0.03701          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 42.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 70.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.403          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      1.28G    0.03957          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 94.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.41          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      1.28G    0.02196          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 41.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 71.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.367          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      1.28G    0.01614          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 39.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 65.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.399          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.007 hours.\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_classifier7/weights/last.pt, 31.7MB\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_classifier7/weights/best.pt, 31.7MB\n",
      "\n",
      "Validating /data/konrad/workspace/training_log/yolo_classifier7/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,766,499 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 1065 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 283 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 694 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 21.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.406          1\n",
      "Speed: 0.2ms preprocess, 1.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier7\u001b[0m\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier7\u001b[0m\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CPU (AMD Ryzen Threadripper PRO 5975WX 32-Cores)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,766,499 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/data/konrad/workspace/training_log/yolo_classifier7/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 3) (30.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1+cu121...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 0.5s, saved as '/data/konrad/workspace/training_log/yolo_classifier7/weights/best.torchscript' (60.4 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier7/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/data/konrad/workspace/training_log/yolo_classifier7/weights/best.torchscript imgsz=224  \n",
      "Validate:        yolo val task=classify model=/data/konrad/workspace/training_log/yolo_classifier7/weights/best.torchscript imgsz=224 data=/data/konrad/workspace/datasets/yolo_classify_loco  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/konrad/workspace/training_log/yolo_classifier7/weights/best.torchscript'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Rotate(limit=(10, 20), p=.7),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3,9), p=.7),\n",
    "        A.MedianBlur(blur_limit=7, p=.7),\n",
    "    ], p=.6),\n",
    "    A.Sharpen(p=.7),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))\n",
    "\n",
    "num_gen = 5\n",
    "\n",
    "delete_dir_if_exists(IMAGE_DIR)\n",
    "df_to_yolo(train_df, IMAGE_DIR + '/train', transforms = transforms, num_gen=num_gen)\n",
    "# df_to_yolo(train_df, IMAGE_DIR + '/train', img_src_dir = IMAGE_DIR, transforms = None, num_gen=num_gen)\n",
    "df_to_yolo(valid_df, IMAGE_DIR + '/val')\n",
    "df_to_yolo(test_df, IMAGE_DIR + '/test')\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8m-cls.pt\")  # load a pretrained model (recommended for training)\n",
    "epoch = 10\n",
    "\n",
    "model_name = \"yolo_classifier\"\n",
    "# yml_file_path = set_yml(f\"{model_name}_{dataset_type}\", IMAGE_DIR, id2label)\n",
    "results = model.train(data=IMAGE_DIR, epochs=epoch, project=ROOT_DIR + \"/training_log\", name=model_name, cfg=\"config.yml\")\n",
    "# results = model.train(data=\"yolo_detect.yml\", epochs=epoch, project=ROOT_DIR + \"/training_log\", name=\"yolo_detect\")\n",
    "# results = model.val(data=IMAGE_DIR, split='test')  # Evaluate on test set\n",
    "\n",
    "model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c44195e-5516-45cb-af31-0271d95d6bd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/data/konrad/workspace/datasets/yolo_classify_loco' deleted\n",
      "Done !\n",
      "Done !\n",
      "Done !\n",
      "New https://pypi.org/project/ultralytics/8.2.83 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=/data/konrad/workspace/datasets/yolo_classify_loco, epochs=10, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=/data/konrad/workspace/training_log, name=yolo_classifier, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/data/konrad/workspace/training_log/yolo_classifier\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 213 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 694 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 283 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    989443  ultralytics.nn.modules.head.Classify         [768, 3]                      \n",
      "YOLOv8m-cls summary: 141 layers, 15,776,179 parameters, 15,776,179 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /data/konrad/workspace/training_log/yolo_classifier', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/train... 213 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 213/\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/val... 694 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 694/694 \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      1.03G      1.124          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 14.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 62.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.388          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      1.22G      1.079          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 44.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 84.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.434          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       1.2G      1.073          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 51.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 85.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.545          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10       1.2G      1.012          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 55.83it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 85.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.535          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10       1.2G     0.9695          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 53.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 82.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.509          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      1.17G     0.9367          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 53.37it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 81.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.488          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      1.22G     0.8884          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 54.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 83.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.493          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      1.17G     0.8391          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 55.60it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 82.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.494          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      1.22G     0.7801          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 53.50it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 81.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.486          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      1.28G     0.7733          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 56.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 82.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.487          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.003 hours.\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_classifier/weights/last.pt, 31.7MB\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_classifier/weights/best.pt, 31.7MB\n",
      "\n",
      "Validating /data/konrad/workspace/training_log/yolo_classifier/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,766,499 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 213 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 694 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 283 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 44.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.545          1\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier\u001b[0m\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier\u001b[0m\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,766,499 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 213 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 694 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 283 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/test... 283 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 283/28\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.392          1\n",
      "Speed: 0.0ms preprocess, 1.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier2\u001b[0m\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CPU (AMD Ryzen Threadripper PRO 5975WX 32-Cores)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/data/konrad/workspace/training_log/yolo_classifier/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 3) (30.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1+cu121...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 0.5s, saved as '/data/konrad/workspace/training_log/yolo_classifier/weights/best.torchscript' (60.4 MB)\n",
      "\n",
      "Export complete (1.7s)\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/data/konrad/workspace/training_log/yolo_classifier/weights/best.torchscript imgsz=224  \n",
      "Validate:        yolo val task=classify model=/data/konrad/workspace/training_log/yolo_classifier/weights/best.torchscript imgsz=224 data=/data/konrad/workspace/datasets/yolo_classify_loco  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/konrad/workspace/training_log/yolo_classifier/weights/best.torchscript'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Rotate(limit=(10, 20), p=.7),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3,9), p=.7),\n",
    "        A.MedianBlur(blur_limit=7, p=.7),\n",
    "    ], p=.6),\n",
    "    A.Sharpen(p=.7),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))\n",
    "\n",
    "delete_dir_if_exists(IMAGE_DIR)\n",
    "# df_to_yolo(train_df, IMAGE_DIR + '/train', img_src_dir = IMAGE_DIR, transforms = transforms, num_gen=num_gen)\n",
    "df_to_yolo(train_df, IMAGE_DIR + '/train', transforms = None, num_gen=num_gen)\n",
    "df_to_yolo(valid_df, IMAGE_DIR + '/test')\n",
    "df_to_yolo(test_df, IMAGE_DIR + '/val')\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8m-cls.pt\")  # load a pretrained model (recommended for training)\n",
    "epoch = 10\n",
    "\n",
    "model_name = \"yolo_classifier\"\n",
    "# yml_file_path = set_yml(f\"{model_name}_{dataset_type}\", IMAGE_DIR, id2label)\n",
    "# results = model.train(data=yml_file_path, epochs=epoch, project=ROOT_DIR + \"/training_log\", name=\"yolo_detect\", cfg=\"config.yml\")\n",
    "results = model.train(data=IMAGE_DIR, epochs=epoch, project=ROOT_DIR + \"/training_log\", name=model_name)\n",
    "results = model.val(data=IMAGE_DIR, split='test')  # Evaluate on test set\n",
    "\n",
    "model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5be0c21-cc03-4cf3-99ea-f291147b3135",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/data/konrad/workspace/datasets/yolo_classify_loco' deleted\n",
      "Done !\n",
      "Done !\n",
      "Done !\n",
      "New https://pypi.org/project/ultralytics/8.2.83 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=/data/konrad/workspace/datasets/yolo_classify_loco, epochs=10, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=/data/konrad/workspace/training_log, name=yolo_classifier3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0, scale=0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.8, bgr=0.0, mosaic=0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0, crop_fraction=1, cfg=config.yml, tracker=botsort.yaml, save_dir=/data/konrad/workspace/training_log/yolo_classifier3\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 1065 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 694 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 283 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    989443  ultralytics.nn.modules.head.Classify         [768, 3]                      \n",
      "YOLOv8m-cls summary: 141 layers, 15,776,179 parameters, 15,776,179 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /data/konrad/workspace/training_log/yolo_classifier3', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/train... 1065 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 106\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/val... 694 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 694/694 \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 224 train, 224 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      1.46G      1.058          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 38.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 84.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.506          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10       1.2G     0.6942          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 42.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 72.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.439          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      1.19G      0.224          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 43.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 64.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.427          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      1.19G    0.09843          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 48.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 85.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.406          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      1.19G    0.07085          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 46.74it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 78.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.45          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      1.19G    0.04371          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 42.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 70.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.445          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      1.19G    0.03549          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 50.27it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 77.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.486          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      1.19G    0.04699          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 47.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 82.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.431          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      1.19G    0.02648          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 40.89it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 70.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.464          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      1.19G    0.01846          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 49.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 72.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.463          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.029 hours.\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_classifier3/weights/last.pt, 31.7MB\n",
      "Optimizer stripped from /data/konrad/workspace/training_log/yolo_classifier3/weights/best.pt, 31.7MB\n",
      "\n",
      "Validating /data/konrad/workspace/training_log/yolo_classifier3/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,766,499 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 1065 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 694 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 283 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 42.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.506          1\n",
      "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier3\u001b[0m\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier3\u001b[0m\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24115MiB)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,766,499 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/train... found 1065 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/val... found 694 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /data/konrad/workspace/datasets/yolo_classify_loco/test... found 283 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /data/konrad/workspace/datasets/yolo_classify_loco/test... 283 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 283/28\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /data/konrad/workspace/datasets/yolo_classify_loco/test.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 39.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.385          1\n",
      "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier32\u001b[0m\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CPU (AMD Ryzen Threadripper PRO 5975WX 32-Cores)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/data/konrad/workspace/training_log/yolo_classifier3/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 3) (30.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1+cu121...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 0.5s, saved as '/data/konrad/workspace/training_log/yolo_classifier3/weights/best.torchscript' (60.4 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1m/data/konrad/workspace/training_log/yolo_classifier3/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/data/konrad/workspace/training_log/yolo_classifier3/weights/best.torchscript imgsz=224  \n",
      "Validate:        yolo val task=classify model=/data/konrad/workspace/training_log/yolo_classifier3/weights/best.torchscript imgsz=224 data=/data/konrad/workspace/datasets/yolo_classify_loco  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/konrad/workspace/training_log/yolo_classifier3/weights/best.torchscript'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Rotate(limit=(10, 20), p=.7),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3,9), p=.7),\n",
    "        A.MedianBlur(blur_limit=7, p=.7),\n",
    "    ], p=.6),\n",
    "    A.Sharpen(p=.7),\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']))\n",
    "\n",
    "num_gen = 5\n",
    "\n",
    "delete_dir_if_exists(IMAGE_DIR)\n",
    "df_to_yolo(train_df, IMAGE_DIR + '/train', transforms = transforms, num_gen=num_gen)\n",
    "# df_to_yolo(train_df, IMAGE_DIR + '/train', img_src_dir = IMAGE_DIR, transforms = None, num_gen=num_gen)\n",
    "df_to_yolo(valid_df, IMAGE_DIR + '/test')\n",
    "df_to_yolo(test_df, IMAGE_DIR + '/val')\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8m-cls.pt\")  # load a pretrained model (recommended for training)\n",
    "epoch = 10\n",
    "\n",
    "model_name = \"yolo_classifier\"\n",
    "# yml_file_path = set_yml(f\"{model_name}_{dataset_type}\", IMAGE_DIR, id2label)\n",
    "results = model.train(data=IMAGE_DIR, epochs=epoch, project=ROOT_DIR + \"/training_log\", name=model_name, cfg=\"config.yml\")\n",
    "# results = model.train(data=\"yolo_detect.yml\", epochs=epoch, project=ROOT_DIR + \"/training_log\", name=\"yolo_detect\")\n",
    "results = model.val(data=IMAGE_DIR, split='test')  # Evaluate on test set\n",
    "\n",
    "model.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main_env)",
   "language": "python",
   "name": "x_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

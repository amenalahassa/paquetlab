{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786344dd-059c-4d24-90c3-43afe58ad595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import moviepy\n",
    "import moviepy.editor as mp\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import av\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import moviepy\n",
    "import moviepy.editor as mp\n",
    "from IPython.display import clear_output\n",
    "import tempfile\n",
    "import seaborn as sns\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import cv2\n",
    "\n",
    "# from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1b1793-7628-4ef8-a160-c84155f0346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to determine the state based on conditions\n",
    "def determine_state(row):\n",
    "    if row['Healthy']:\n",
    "        return 'Healthy'\n",
    "    elif row['Diarrhé'] and row['Pneumonie']:\n",
    "        return 'Diarrhé_Pneumonie'\n",
    "    elif row['Diarrhé']:\n",
    "        return 'Diarrhé'\n",
    "    elif row['Pneumonie']:\n",
    "        return 'Pneumonie'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def format_time(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "\n",
    "# Function to sample uniformly\n",
    "def uniform_sample(df, sample_size, groupby_cols):\n",
    "    # Calculate the number of rows to sample per group\n",
    "    num_groups = df.groupby(groupby_cols).ngroups\n",
    "    sample_per_group = max(sample_size // num_groups, 1)\n",
    "    \n",
    "    # Sample uniformly within each group\n",
    "    sampled_df = df.groupby(groupby_cols, group_keys=False).apply(lambda x: x.sample(min(len(x), sample_per_group)))\n",
    "    \n",
    "    # If we sampled less than the desired sample_size due to group sizes, sample more from the remaining dataframe\n",
    "    # if len(sampled_df) < sample_size:\n",
    "    #     remaining_sample_size = sample_size - len(sampled_df)\n",
    "    #     remaining_df = df[~df.index.isin(sampled_df.index)]\n",
    "    #     additional_samples = remaining_df.sample(min(len(remaining_df), remaining_sample_size))\n",
    "    #     sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "# Function to sample uniformly with specified values\n",
    "def uniform_sample_with_values(df, sample_size, groupby_cols, filter_values = None):\n",
    "    copy = df.copy(deep=True)\n",
    "    # Filter dataframe based on specified values for each column\n",
    "    if filter_values is not None:\n",
    "        for col, values in filter_values.items():\n",
    "            copy = copy[copy[col].isin(values)]\n",
    "    \n",
    "    # Calculate the number of rows to sample per group\n",
    "    num_groups = copy.groupby(groupby_cols).ngroups\n",
    "    sample_per_group = max(sample_size // num_groups, 1)\n",
    "    \n",
    "    # Sample uniformly within each group\n",
    "    sampled_df = copy.groupby(groupby_cols, group_keys=False).apply(lambda x: x.sample(min(len(x), sample_per_group)))\n",
    "    \n",
    "    # If we sampled less than the desired sample_size due to group sizes, sample more from the remaining dataframe\n",
    "    if len(sampled_df) < sample_size:\n",
    "        remaining_sample_size = sample_size - len(sampled_df)\n",
    "        remaining_df = copy[~copy.index.isin(sampled_df.index)]\n",
    "        additional_samples = remaining_df.sample(min(len(remaining_df), remaining_sample_size))\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    \n",
    "    return sampled_df, copy[~copy.index.isin(sampled_df.index)]\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    '''\n",
    "    Sample a given number of frame indices from the video.\n",
    "    Args:\n",
    "        clip_len (`int`): Total number of frames to sample.\n",
    "        frame_sample_rate (`int`): Sample every n-th frame.\n",
    "        seg_len (`int`): Maximum allowed index of sample's last frame.\n",
    "    Returns:\n",
    "        indices (`List[int]`): List of sampled frame indices\n",
    "    '''\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    if converted_len >= seg_len:\n",
    "        end_idx = seg_len\n",
    "    else:\n",
    "        end_idx = np.random.randint(converted_len, seg_len)\n",
    "    # start_idx = end_idx - converted_len\n",
    "    # start_idx = clip_len\n",
    "    start_idx = 0\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def plot_results(pil_img, scores, boxes, labels, masks=None):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    np_image = np.array(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    if masks is None:\n",
    "      masks = [None for _ in range(len(scores))]\n",
    "        \n",
    "    assert len(scores) == len(boxes) == len(labels) == len(masks)\n",
    "    \n",
    "    for s, (xmin, ymin, xmax, ymax), l, mask, c in zip(scores, boxes.tolist(), labels, masks, colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        text = f'{l}: {s:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "        if mask is None:\n",
    "          continue\n",
    "        np_image = apply_mask(np_image, mask, c)\n",
    "\n",
    "        padded_mask = np.zeros((mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "          verts = np.fliplr(verts) - 1\n",
    "          p = Polygon(verts, facecolor=\"none\", edgecolor=c)\n",
    "          ax.add_patch(p)\n",
    "\n",
    "\n",
    "    plt.imshow(np_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_res(results, ax, color='green'):\n",
    "\n",
    "    bboxes = results['boxes']\n",
    "    labels = results['labels']\n",
    "    scores = results['scores']\n",
    "\n",
    "    colors = ['purple', 'yellow', 'red', 'green', 'orange', 'pink']\n",
    "    \n",
    "    for i, (b, ll, ss) in enumerate(zip(bboxes, labels, scores)):\n",
    "        ax.add_patch(plt.Rectangle((b[0], b[1]), b[2] - b[0], b[3] - b[1], fill=False, color=colors[i], linewidth=3))\n",
    "        cls_name = ll if isinstance(ll,str) else CLASSES[ll]\n",
    "        text = f'{cls_name}: {ss:.2f}'\n",
    "        print(text)\n",
    "        ax.text(b[0], b[1], text, fontsize=15, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "\n",
    "def plot_gallery(image_paths, n_cols=5):\n",
    "    n_images = len(image_paths)\n",
    "    n_rows = n_images // n_cols + int(n_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(20, n_rows * 4))\n",
    "    print(n_rows, n_cols)\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        img = Image.open(image_path)\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()   \n",
    "\n",
    "def plot_bbox_gallery(image_df, n_cols=5):\n",
    "    n_images = image_df.shape[0]\n",
    "    n_rows = n_images // n_cols + int(n_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(20, n_rows * 4))\n",
    "    for i, row in image_df.iterrows():\n",
    "        img = Image.open(row[\"path\"])\n",
    "        # plt.subplot(n_rows, n_cols, i + 1)\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        # ax = plt.gca()\n",
    "        score = row[\"conf\"]\n",
    "        box_x = row[\"box_x\"]\n",
    "        box_y = row[\"box_y\"]\n",
    "        box_width = row[\"box_width\"]\n",
    "        box_height = row[\"box_height\"]\n",
    "        box_x = box_x - (box_width / 2)\n",
    "        box_y = box_y - (box_height / 2)\n",
    "        rect = plt.Rectangle((box_x, box_y), box_width, box_height, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(box_x, box_y - 10, f' {score:.2f}', color='red', fontsize=12, backgroundcolor='white')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401cd440-0ba0-4036-8810-b57b9704d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_medias(aptms, mp4_files, root_dir, frame_sample_rate = 4, num_images = 16, bbox_conf = (.8, .5), delta = 20, step = 0, video_model = None,  image_model = None):\n",
    "    \n",
    "    size = len(aptms)\n",
    "    video_records = []\n",
    "    image_records = []\n",
    "    indices_records = []\n",
    "    for idx in tqdm(range(size), desc=\"Processing items\"):\n",
    "        one_row = aptms.iloc[idx]\n",
    "        target = one_row['State']\n",
    "            \n",
    "        cond = (\n",
    "            (mp4_files[\"start_date\"] == one_row.datetime.date())\n",
    "            # (mp4_files[\"start_date\"] == str(one_row.datetime.date()))\n",
    "            & (mp4_files[\"start_time\"] <= one_row.datetime)\n",
    "            & (mp4_files[\"end_time\"] > one_row.datetime)\n",
    "            & (mp4_files[\"station\"] == one_row.parc)\n",
    "        )\n",
    "\n",
    "        if mp4_files[cond].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        video_dir_path = root_dir + \"/videos/\" + target\n",
    "        if not os.path.exists(video_dir_path):\n",
    "            os.makedirs(video_dir_path)\n",
    "\n",
    "        image_dir_path = root_dir + \"/images/\" + target\n",
    "        if not os.path.exists(image_dir_path):\n",
    "            os.makedirs(image_dir_path)\n",
    "\n",
    "        for index, file in mp4_files[cond].iterrows():\n",
    "            zero = (one_row[\"datetime\"] - file[\"start_time\"]).total_seconds()\n",
    "            if zero - delta > 0:\n",
    "                break\n",
    "    \n",
    "        video = mp.VideoFileClip(file[\"path\"])\n",
    "        start_at = max(zero - delta, 0)\n",
    "        end_at = max(zero - step, 0)\n",
    "        \n",
    "        # if end_at <= start_at or (end_at - start_at) <= 1:\n",
    "        if end_at <= start_at or (end_at - start_at) < delta - step:\n",
    "            continue\n",
    "\n",
    "        # print(zero, start_at, end_at, file)\n",
    "            \n",
    "        clip = video.subclip(start_at, end_at)\n",
    "        nfaces = 0\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(suffix='.mp4') as tmpfile:\n",
    "            clip.write_videofile(tmpfile.name, logger= None)\n",
    "            container = av.open(tmpfile.name)\n",
    "\n",
    "            video_stream = container.streams.video[0]\n",
    "\n",
    "            # Get the duration in time base units\n",
    "            duration_in_units = video_stream.duration\n",
    "            \n",
    "            # Get the time base\n",
    "            time_base = video_stream.time_base\n",
    "            \n",
    "            # Calculate the duration in seconds\n",
    "            duration_in_seconds = duration_in_units * time_base\n",
    "\n",
    "            # Sample 16 frames\n",
    "            fps = int(container.streams.video[0].average_rate)\n",
    "            seg_len = int(duration_in_seconds) * fps\n",
    "            sample_rate = min(int(seg_len // num_images), frame_sample_rate)\n",
    "            indices = sample_frame_indices(clip_len=num_images, frame_sample_rate=sample_rate, seg_len=seg_len)\n",
    "            video_frames = read_video_pyav(container, indices)\n",
    "            image_frames = [Image.fromarray(frame) for frame in video_frames]\n",
    "        #     video_images = [Image.fromarray(frame) for frame in video_frames]\n",
    "        #     results = video_model.predict(video_images, save=False, imgsz=640, conf=bbox_conf[1], max_det=1, show=False)\n",
    "\n",
    "        #     frames_idx = []\n",
    "        #     image_frames = []\n",
    "        #     for i, r in enumerate(results):\n",
    "        #         if r.boxes.shape[0] != 0:\n",
    "        #             nfaces += 1\n",
    "        #             frames_idx.append(indices[i])\n",
    "        #             image_frames.append(video_images[i])\n",
    "                    \n",
    "        #         # else:\n",
    "        #             # nfaces = 0\n",
    "                    \n",
    "        # if nfaces < 1:\n",
    "        # # if nfaces < 5:\n",
    "        #     continue\n",
    "\n",
    "        results = image_model.predict(image_frames, save=False, imgsz=640, conf=bbox_conf[0], max_det=1, show=False)\n",
    "        result_records = []\n",
    "        image_indices = []\n",
    "        for frame_id, r in enumerate(results):\n",
    "            if r.boxes.shape[0] == 0:\n",
    "                continue\n",
    "                # conf = 0\n",
    "                # x1, y1, width, height = 0, 0, 0, 0\n",
    "            else:\n",
    "                conf = r.boxes.cpu().numpy().conf[0]\n",
    "                x1, y1, width, height =  r.boxes.cpu().numpy().xywh[0]\n",
    "\n",
    "            img = image_frames[frame_id]\n",
    "            # filename = f\"image_{frames_idx[frame_id]}_{idx}_{frame_id}_{one_row['calfNumber']}_{one_row['parc']}_{one_row['datetime']}_{target}.png\"\n",
    "            filename = f\"image_{idx}_{frame_id}_{one_row['calfNumber']}_{one_row['parc']}_{one_row['datetime']}_{target}.png\"\n",
    "            img_save_path = os.path.join(image_dir_path, filename)\n",
    "            img.save(img_save_path)\n",
    "            # image_indices.append(frames_idx[frame_id])\n",
    "            image_indices.append(indices[frame_id])\n",
    "\n",
    "            result_records.append({\n",
    "                \"image\": filename,\n",
    "                \"path\": img_save_path,\n",
    "                \"label\": target,\n",
    "                \"calf\": one_row[\"calfNumber\"],\n",
    "                \"station\": one_row[\"parc\"],\n",
    "                \"before\": one_row[\"datetime\"],\n",
    "                \"from\": file[\"path\"],\n",
    "                \"conf\": conf, \n",
    "                \"box_x\": x1,\n",
    "                \"box_y\": y1,\n",
    "                \"box_width\": width,\n",
    "                \"box_height\": height,\n",
    "                # \"passed\": r.boxes.shape[0] == 0\n",
    "            })\n",
    "\n",
    "        # if len(result_records) == 0:\n",
    "        if len(result_records) < 1:\n",
    "            continue\n",
    "\n",
    "        nfaces = len(result_records)\n",
    "        \n",
    "        image_records.extend(result_records)\n",
    "        filename = f\"clip_{idx}_{one_row['calfNumber']}_{one_row['parc']}_{one_row['datetime']}_{target}.mp4\"\n",
    "        temp_path = f\"{video_dir_path}/{filename}\"\n",
    "        # temp_path = f\"{dir_path}/{nfaces}_{filename}\"\n",
    "        clip.write_videofile(temp_path, logger= None)\n",
    "        \n",
    "        indices_records.extend([{\"fps\": fps, \"seg_len\": seg_len, \"sample_rate\": sample_rate, \"idx\": idx, \"from\": temp_path} for idx in image_indices])\n",
    "        \n",
    "        video_records.append({\n",
    "            \"video\": filename,\n",
    "            \"path\": temp_path,\n",
    "            \"label\": target,\n",
    "            \"duration\": end_at - start_at,\n",
    "            \"calf\": one_row[\"calfNumber\"],\n",
    "            \"station\": one_row[\"parc\"],\n",
    "            \"before\": one_row[\"datetime\"],\n",
    "            \"from\": file[\"path\"],\n",
    "            \"nfaces\": nfaces\n",
    "        })\n",
    "    \n",
    "    clear_output()\n",
    "    return pd.DataFrame(video_records), pd.DataFrame(image_records), pd.DataFrame(indices_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43f2bbbf-8018-4e54-a405-b62daec2b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "ROOT_DIR = \"/data/konrad/workspace\"\n",
    "states = pd.read_csv(ROOT_DIR +'/csv_files/illness.csv')\n",
    "aptm = pd.read_csv(ROOT_DIR + '/csv_files/visits_point.csv', delimiter=';')\n",
    "\n",
    "DATA_DIR = \"/data/public/heureux_2022-02-16_2022-04-16\"\n",
    "dir_path = DATA_DIR\n",
    "directories = [d for d in os.listdir(dir_path) if d.startswith(\"2022\") and os.path.isdir(os.path.join(dir_path, d))]\n",
    "\n",
    "day_to_dir = {}\n",
    "for d in directories:\n",
    "    if d.startswith(\"2022-\"):\n",
    "        p = d.split(\"-\")\n",
    "        start_date = \"-\".join(p[:3])\n",
    "        end_date = \"-\".join(p[3:])\n",
    "        date_range = pd.date_range(start=start_date, end=end_date)\n",
    "        day_to_dir.update({md:d for md in date_range.strftime('%Y-%m-%d').tolist()})\n",
    "\n",
    "day_to_dir['2022-02-02'] = \"2022_02_02\"\n",
    "\n",
    "mp4_files = []\n",
    "for d in directories:\n",
    "    try:\n",
    "        path = dir_path + \"/\" + d\n",
    "        # print(path)\n",
    "        for f in os.listdir(path):\n",
    "            if f.endswith(\".mp4\") and os.path.isfile(os.path.join(path, f)):\n",
    "                filename = f[:-4].split(\"_\")\n",
    "                start_date = filename[3][:4] + \"-\" + filename[3][4:6] + \"-\" + filename[3][6:8] + \"T\" + filename[3][8:10] + \":\" + filename[3][10:12] + \":\" + filename[3][12:]\n",
    "                end_date = filename[4][:4] + \"-\" + filename[4][4:6] + \"-\" + filename[4][6:8] + \"T\" + filename[4][8:10] + \":\" + filename[4][10:12] + \":\" + filename[4][12:]\n",
    "                station = filename[1][2:]\n",
    "                # print(filename, start_date, end_date, station)\n",
    "                # print(os.path.join(path, f))\n",
    "                mp4_files.append({\"station\": station, \"start_at\": start_date, \"end_at\": end_date, \"path\": os.path.join(path, f)})\n",
    "                # break\n",
    "            \n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "mp4_files = pd.DataFrame(mp4_files)\n",
    "mp4_files[\"start_time\"] = pd.to_datetime(mp4_files[\"start_at\"])\n",
    "mp4_files[\"end_time\"] = pd.to_datetime(mp4_files[\"end_at\"])\n",
    "mp4_files[\"start_date\"] = mp4_files[\"start_time\"].dt.date\n",
    "mp4_files[\"start_hour\"] = mp4_files[\"start_time\"].dt.hour\n",
    "mp4_files[\"start_mn\"] = mp4_files[\"start_time\"].dt.minute\n",
    "mp4_files = mp4_files[mp4_files[\"station\"].isin([\"1\",\"2\",\"9\",\"10\"])]\n",
    "\n",
    "states['State'] = states.apply(determine_state, axis=1)\n",
    "states = states[~states[\"State\"].isna()]\n",
    "\n",
    "columns = [\"calfNumber\", \"station\", \"Duration\", \"localDate\", \"date\", \"feederLong\"]\n",
    "aptm[\"datetime\"] = pd.to_datetime(aptm[\"localDate\"])\n",
    "aptm[\"day\"] = aptm[\"datetime\"].dt.date\n",
    "aptm[\"hour\"] = aptm[\"datetime\"].dt.time\n",
    "\n",
    "# Only data for eval date\n",
    "stated_aptm = aptm[aptm[\"day\"].apply(str).isin(states.date.unique())][columns + [\"day\", \"hour\", \"datetime\"]]\n",
    "stated_aptm[\"parc\"] = None\n",
    "stated_aptm.loc[(stated_aptm[\"station\"]==1) & (stated_aptm[\"feederLong\"]==\"DAL 2 (2496)\"), 'parc']=\"9\" #louve 3\n",
    "stated_aptm.loc[(stated_aptm[\"station\"]==2) & (stated_aptm[\"feederLong\"]==\"DAL 2 (2496)\"), 'parc']=\"10\" #louve 4\n",
    "stated_aptm.loc[(stated_aptm[\"station\"]==2) & (stated_aptm[\"feederLong\"]==\"DAL 1 (2494)\"), 'parc']=\"1\"  #louve 2 \n",
    "stated_aptm.loc[(stated_aptm[\"station\"]==1) & (stated_aptm[\"feederLong\"]==\"DAL 1 (2494)\"), 'parc']=\"2\" #louve 1\n",
    "stated_aptm = stated_aptm[stated_aptm[\"Duration\"] > 0]\n",
    "stated_aptm = stated_aptm[~stated_aptm[\"parc\"].isna()]\n",
    "# Only data for available recorded video dates\n",
    "stated_aptm = stated_aptm[stated_aptm[\"day\"].apply(str).isin(day_to_dir.keys())]\n",
    "# Only apptm for available recorded video hour\n",
    "stated_aptm = stated_aptm[(stated_aptm[\"datetime\"].dt.hour >= 6) & (stated_aptm[\"datetime\"].dt.hour <= 22)]\n",
    "stated_aptm[\"cwd\"] = stated_aptm[\"calfNumber\"].astype(str) + \" \" + stated_aptm[\"day\"].astype(str)\n",
    "states[\"cwd\"] = states[\"No ATQ\"].astype(str) + \" \" + states[\"date\"].astype(str)\n",
    "aptm_with_state = pd.merge(stated_aptm[[\"calfNumber\", \"parc\", \"day\", \"Duration\", \"cwd\", \"datetime\"]], states[[\"State\", \"cwd\"]], on=\"cwd\", how='inner')\n",
    "\n",
    "drop_idx=[]\n",
    "visited_day = {}\n",
    "minutes = 3\n",
    "for idx in aptm_with_state.sort_values(by=\"datetime\").index.values:\n",
    "    key = \"{day}_{parc}\".format(day=aptm_with_state.iloc[idx][\"day\"], parc=aptm_with_state.iloc[idx][\"parc\"])\n",
    "\n",
    "    if not key in visited_day.keys():\n",
    "        visited_day[key] = aptm_with_state.iloc[idx][\"datetime\"] +  pd.Timedelta(seconds=aptm_with_state.iloc[idx][\"Duration\"])\n",
    "        continue\n",
    "    \n",
    "    diff = (aptm_with_state.iloc[idx][\"datetime\"] - visited_day[key]).total_seconds()\n",
    "    \n",
    "    if diff < (minutes * 60):\n",
    "        drop_idx.append(idx)\n",
    "    else:\n",
    "        visited_day[key] = aptm_with_state.iloc[idx][\"datetime\"]\n",
    "\n",
    "spaced_aptm_with_state = aptm_with_state[~aptm_with_state.index.isin(drop_idx)]\n",
    "spaced_aptm_with_state.reset_index(drop=True, inplace=True)\n",
    "\n",
    "root_dir = f\"/data/data_calves/konrad/\"\n",
    "aptm_with_state.to_csv(root_dir + 'aptm_with_state.csv', index=False)\n",
    "spaced_aptm_with_state.to_csv(root_dir + 'spaced_aptm_with_state.csv', index=False)\n",
    "mp4_files.to_csv(root_dir + 'mp4_files.csv', index=False)\n",
    "aptm_sampled = spaced_aptm_with_state[spaced_aptm_with_state[\"State\"].isin(['Diarrhé', 'Pneumonie', 'Healthy', 'Diarrhé, Pneumonie'])]\n",
    "aptm_sampled.to_csv(root_dir + 'usable_aptm_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230e7be-b1fe-463f-afd9-c98489343c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT_DIR = \"/data/konrad/workspace\"\n",
    "# yolo_face = YOLO(ROOT_DIR + \"/models/best-face7.pt\")\n",
    "# yolo_world = YOLO(\"yolov8s-world.pt\")  \n",
    "# yolo_world.set_classes([\"calf face\"])\n",
    "\n",
    "# # Start time\n",
    "# start_time = time.time()\n",
    "\n",
    "# frame = 10\n",
    "# step = 0\n",
    "# frame_sample_rate = 15\n",
    "# num_images = 30\n",
    "# ibbox_conf = .80\n",
    "# vbbox_conf = .50\n",
    "# delta = frame + step\n",
    "# # root_dir = ROOT_DIR + f\"/datasets/mixed_{frame}s_b{step}s\"\n",
    "# # root_dir = f\"/data/data_calves/konrad/mixed_{frame}s_b{step}s\"\n",
    "# root_dir = f\"/data/data_calves/konrad/mixed_{frame}s_b{step}s_f7\"\n",
    "# # root_dir = ROOT_DIR + \"/datasets/videos/train\"\n",
    "\n",
    "# records = extract_medias(aptm_sampled, mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, video_model = yolo_world, image_model = yolo_face, bbox_conf = (ibbox_conf, vbbox_conf))\n",
    "# # records = extract_medias(aptm_sampled.iloc[:100], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, video_model = yolo_world, image_model = yolo_face, bbox_conf = (ibbox_conf, vbbox_conf))\n",
    "# # records = extract_videos_mdetr(aptm_sampled.iloc[:100], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\n",
    "# # records = extract_videos(aptm_sampled.iloc[:100], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\n",
    "# # records = extract_videos(aptm_sampled, mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\n",
    "# # records = extract_videos(aptm_sampled.iloc[:10], mp4_files, root_dir, delta = delta, step = step)\n",
    "# # records = extract_videos(aptm_sampled, mp4_files, root_dir, delta = delta, step = step)\n",
    "\n",
    "# # End time\n",
    "# end_time = time.time()\n",
    "\n",
    "# # Calculate elapsed time\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# formatted_time = format_time(elapsed_time)\n",
    "# records[0].to_csv(root_dir + '/videos_metadata.csv', index=False)\n",
    "# records[1].to_csv(root_dir + '/images_metadata.csv', index=False)\n",
    "# records[2].to_csv(root_dir + '/indices_metadata.csv', index=False)\n",
    "# # records.to_csv('train_video_extracted_metadata.csv', index=False)\n",
    "\n",
    "# # Display the elapsed time\n",
    "# print(f\"Time of execution: {formatted_time} from {elapsed_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main_env)",
   "language": "python",
   "name": "x_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

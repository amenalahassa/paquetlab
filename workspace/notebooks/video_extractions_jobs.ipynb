{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786344dd-059c-4d24-90c3-43afe58ad595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import moviepy\n",
    "import moviepy.editor as mp\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import av\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import moviepy\n",
    "import moviepy.editor as mp\n",
    "from IPython.display import clear_output\n",
    "import tempfile\n",
    "import seaborn as sns\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1b1793-7628-4ef8-a160-c84155f0346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to determine the state based on conditions\n",
    "def determine_state(row):\n",
    "    if row['Healthy']:\n",
    "        return 'Healthy'\n",
    "    elif row['Diarrhé'] and row['Pneumonie']:\n",
    "        return 'Diarrhé_Pneumonie'\n",
    "    elif row['Diarrhé']:\n",
    "        return 'Diarrhé'\n",
    "    elif row['Pneumonie']:\n",
    "        return 'Pneumonie'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def format_time(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "\n",
    "# Function to sample uniformly\n",
    "def uniform_sample(df, sample_size, groupby_cols):\n",
    "    # Calculate the number of rows to sample per group\n",
    "    num_groups = df.groupby(groupby_cols).ngroups\n",
    "    sample_per_group = max(sample_size // num_groups, 1)\n",
    "    \n",
    "    # Sample uniformly within each group\n",
    "    sampled_df = df.groupby(groupby_cols, group_keys=False).apply(lambda x: x.sample(min(len(x), sample_per_group)))\n",
    "    \n",
    "    # If we sampled less than the desired sample_size due to group sizes, sample more from the remaining dataframe\n",
    "    # if len(sampled_df) < sample_size:\n",
    "    #     remaining_sample_size = sample_size - len(sampled_df)\n",
    "    #     remaining_df = df[~df.index.isin(sampled_df.index)]\n",
    "    #     additional_samples = remaining_df.sample(min(len(remaining_df), remaining_sample_size))\n",
    "    #     sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "# Function to sample uniformly with specified values\n",
    "def uniform_sample_with_values(df, sample_size, groupby_cols, filter_values = None):\n",
    "    copy = df.copy(deep=True)\n",
    "    # Filter dataframe based on specified values for each column\n",
    "    if filter_values is not None:\n",
    "        for col, values in filter_values.items():\n",
    "            copy = copy[copy[col].isin(values)]\n",
    "    \n",
    "    # Calculate the number of rows to sample per group\n",
    "    num_groups = copy.groupby(groupby_cols).ngroups\n",
    "    sample_per_group = max(sample_size // num_groups, 1)\n",
    "    \n",
    "    # Sample uniformly within each group\n",
    "    sampled_df = copy.groupby(groupby_cols, group_keys=False).apply(lambda x: x.sample(min(len(x), sample_per_group)))\n",
    "    \n",
    "    # If we sampled less than the desired sample_size due to group sizes, sample more from the remaining dataframe\n",
    "    if len(sampled_df) < sample_size:\n",
    "        remaining_sample_size = sample_size - len(sampled_df)\n",
    "        remaining_df = copy[~copy.index.isin(sampled_df.index)]\n",
    "        additional_samples = remaining_df.sample(min(len(remaining_df), remaining_sample_size))\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    \n",
    "    return sampled_df, copy[~copy.index.isin(sampled_df.index)]\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    '''\n",
    "    Decode the video with PyAV decoder.\n",
    "    Args:\n",
    "        container (`av.container.input.InputContainer`): PyAV container.\n",
    "        indices (`List[int]`): List of frame indices to decode.\n",
    "    Returns:\n",
    "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
    "    '''\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    '''\n",
    "    Sample a given number of frame indices from the video.\n",
    "    Args:\n",
    "        clip_len (`int`): Total number of frames to sample.\n",
    "        frame_sample_rate (`int`): Sample every n-th frame.\n",
    "        seg_len (`int`): Maximum allowed index of sample's last frame.\n",
    "    Returns:\n",
    "        indices (`List[int]`): List of sampled frame indices\n",
    "    '''\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    if converted_len >= seg_len:\n",
    "        end_idx = seg_len\n",
    "    else:\n",
    "        end_idx = np.random.randint(converted_len, seg_len)\n",
    "    # start_idx = end_idx - converted_len\n",
    "    # start_idx = clip_len\n",
    "    start_idx = 0\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Apply the given mask to the image.\n",
    "    \"\"\"\n",
    "    for c in range(3):\n",
    "        image[:, :, c] = np.where(mask == 1,\n",
    "                                  image[:, :, c] *\n",
    "                                  (1 - alpha) + alpha * color[c] * 255,\n",
    "                                  image[:, :, c])\n",
    "    return image\n",
    "\n",
    "def plot_results(pil_img, scores, boxes, labels, masks=None):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    np_image = np.array(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    if masks is None:\n",
    "      masks = [None for _ in range(len(scores))]\n",
    "        \n",
    "    assert len(scores) == len(boxes) == len(labels) == len(masks)\n",
    "    \n",
    "    for s, (xmin, ymin, xmax, ymax), l, mask, c in zip(scores, boxes.tolist(), labels, masks, colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        text = f'{l}: {s:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "        if mask is None:\n",
    "          continue\n",
    "        np_image = apply_mask(np_image, mask, c)\n",
    "\n",
    "        padded_mask = np.zeros((mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "          verts = np.fliplr(verts) - 1\n",
    "          p = Polygon(verts, facecolor=\"none\", edgecolor=c)\n",
    "          ax.add_patch(p)\n",
    "\n",
    "\n",
    "    plt.imshow(np_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def add_res(results, ax, color='green'):\n",
    "\n",
    "    bboxes = results['boxes']\n",
    "    labels = results['labels']\n",
    "    scores = results['scores']\n",
    "\n",
    "    colors = ['purple', 'yellow', 'red', 'green', 'orange', 'pink']\n",
    "    \n",
    "    for i, (b, ll, ss) in enumerate(zip(bboxes, labels, scores)):\n",
    "        ax.add_patch(plt.Rectangle((b[0], b[1]), b[2] - b[0], b[3] - b[1], fill=False, color=colors[i], linewidth=3))\n",
    "        cls_name = ll if isinstance(ll,str) else CLASSES[ll]\n",
    "        text = f'{cls_name}: {ss:.2f}'\n",
    "        print(text)\n",
    "        ax.text(b[0], b[1], text, fontsize=15, bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "\n",
    "def plot_gallery(image_paths, n_cols=5):\n",
    "    n_images = len(image_paths)\n",
    "    n_rows = n_images // n_cols + int(n_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(20, n_rows * 4))\n",
    "    print(n_rows, n_cols)\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        img = Image.open(image_path)\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()   \n",
    "\n",
    "def plot_bbox_gallery(image_df, n_cols=5):\n",
    "    n_images = image_df.shape[0]\n",
    "    n_rows = n_images // n_cols + int(n_images % n_cols > 0)\n",
    "    \n",
    "    plt.figure(figsize=(20, n_rows * 4))\n",
    "    for i, row in image_df.iterrows():\n",
    "        img = Image.open(row[\"path\"])\n",
    "        # plt.subplot(n_rows, n_cols, i + 1)\n",
    "        ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "        plt.imshow(img)\n",
    "        # ax = plt.gca()\n",
    "        score = row[\"conf\"]\n",
    "        box_x = row[\"box_x\"]\n",
    "        box_y = row[\"box_y\"]\n",
    "        box_width = row[\"box_width\"]\n",
    "        box_height = row[\"box_height\"]\n",
    "        box_x = box_x - (box_width / 2)\n",
    "        box_y = box_y - (box_height / 2)\n",
    "        rect = plt.Rectangle((box_x, box_y), box_width, box_height, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(box_x, box_y - 10, f' {score:.2f}', color='red', fontsize=12, backgroundcolor='white')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401cd440-0ba0-4036-8810-b57b9704d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_medias(aptms, mp4_files, root_dir, frame_sample_rate = 4, num_images = 16, bbox_conf = (.8, .5), delta = 20, step = 0, video_model = None,  image_model = None):\n",
    "    \n",
    "    size = len(aptms)\n",
    "    video_records = []\n",
    "    image_records = []\n",
    "    indices_records = []\n",
    "    for idx in tqdm(range(size), desc=\"Processing items\"):\n",
    "        one_row = aptms.iloc[idx]\n",
    "        target = one_row['State']\n",
    "        when = one_row['datetime'].strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            \n",
    "        cond = (\n",
    "            (mp4_files[\"start_date\"] == one_row.datetime.date())\n",
    "            & (mp4_files[\"start_time\"] <= one_row.datetime)\n",
    "            & (mp4_files[\"end_time\"] > one_row.datetime)\n",
    "            & (mp4_files[\"station\"] == one_row.parc)\n",
    "        )\n",
    "\n",
    "        if mp4_files[cond].shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        video_dir_path = root_dir + \"/videos/\" + target\n",
    "        if not os.path.exists(video_dir_path):\n",
    "            os.makedirs(video_dir_path)\n",
    "\n",
    "        image_dir_path = root_dir + \"/images/\" + target\n",
    "        if not os.path.exists(image_dir_path):\n",
    "            os.makedirs(image_dir_path)\n",
    "\n",
    "        for index, file in mp4_files[cond].iterrows():\n",
    "            zero = (one_row[\"datetime\"] - file[\"start_time\"]).total_seconds()\n",
    "            if zero - delta > 0:\n",
    "                break\n",
    "    \n",
    "        video = mp.VideoFileClip(file[\"path\"])\n",
    "        start_at = max(zero - delta, 0)\n",
    "        end_at = max(zero - step, 0)\n",
    "        \n",
    "        # if end_at <= start_at or (end_at - start_at) <= 1:\n",
    "        if end_at <= start_at or (end_at - start_at) < delta - step:\n",
    "            continue\n",
    "\n",
    "        # print(zero, start_at, end_at, file)\n",
    "            \n",
    "        clip = video.subclip(start_at, end_at)\n",
    "        video_filename = f\"clip_{idx}_{one_row['calfNumber']}_{one_row['parc']}_{when}_{target}.mp4\"\n",
    "        video_path = f\"{video_dir_path}/{video_filename}\"\n",
    "        nfaces = 0\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(suffix='.mp4') as tmpfile:\n",
    "            clip.write_videofile(tmpfile.name, logger= None)\n",
    "            container = av.open(tmpfile.name)\n",
    "\n",
    "            video_stream = container.streams.video[0]\n",
    "\n",
    "            # Get the duration in time base units\n",
    "            duration_in_units = video_stream.duration\n",
    "            \n",
    "            # Get the time base\n",
    "            time_base = video_stream.time_base\n",
    "            \n",
    "            # Calculate the duration in seconds\n",
    "            duration_in_seconds = duration_in_units * time_base\n",
    "\n",
    "            fps = int(container.streams.video[0].average_rate)\n",
    "            seg_len = int(duration_in_seconds) * fps\n",
    "            sample_rate = min(int(seg_len // num_images), frame_sample_rate)\n",
    "            indices = sample_frame_indices(clip_len=num_images, frame_sample_rate=sample_rate, seg_len=seg_len)\n",
    "            video_frames = read_video_pyav(container, indices)\n",
    "            image_frames = [Image.fromarray(frame) for frame in video_frames]\n",
    "\n",
    "        results = image_model.predict(image_frames, save=False, imgsz=640, conf=bbox_conf[0], max_det=1, show=False)\n",
    "        result_records = []\n",
    "        image_indices = []\n",
    "\n",
    "        \n",
    "        for frame_id, r in enumerate(results):\n",
    "            if r.boxes.shape[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                conf = r.boxes.cpu().numpy().conf[0]\n",
    "                x1, y1, width, height =  r.boxes.cpu().numpy().xywh[0]\n",
    "\n",
    "            img = image_frames[frame_id]\n",
    "            filename = f\"image_{idx}_{frame_id}_{one_row['calfNumber']}_{one_row['parc']}_{when}_{target}.png\"\n",
    "            img_save_path = os.path.join(image_dir_path, filename)\n",
    "            img.save(img_save_path)\n",
    "            image_indices.append(indices[frame_id])\n",
    "\n",
    "            result_records.append({\n",
    "                \"image\": filename,\n",
    "                \"path\": img_save_path,\n",
    "                \"label\": target,\n",
    "                \"calf\": one_row[\"calfNumber\"],\n",
    "                \"station\": one_row[\"parc\"],\n",
    "                \"before\": one_row[\"datetime\"],\n",
    "                \"from\": file[\"path\"],\n",
    "                \"conf\": conf, \n",
    "                \"box_x\": x1,\n",
    "                \"box_y\": y1,\n",
    "                \"box_width\": width,\n",
    "                \"box_height\": height,\n",
    "                \"video\": video_filename\n",
    "            })\n",
    "\n",
    "        # if len(result_records) == 0:\n",
    "        if len(result_records) < 1:\n",
    "            continue\n",
    "\n",
    "        nfaces = len(result_records)\n",
    "        clip.write_videofile(video_path, logger= None)\n",
    "        \n",
    "        indices_records.extend([{\"fps\": fps, \"seg_len\": seg_len, \"sample_rate\": sample_rate, \"idx\": idx, \"from\": video_path} for idx in image_indices])\n",
    "        \n",
    "        video_records.append({\n",
    "            \"video\": video_filename,\n",
    "            \"path\": video_path,\n",
    "            \"label\": target,\n",
    "            \"duration\": end_at - start_at,\n",
    "            \"calf\": one_row[\"calfNumber\"],\n",
    "            \"station\": one_row[\"parc\"],\n",
    "            \"before\": one_row[\"datetime\"],\n",
    "            \"from\": file[\"path\"],\n",
    "            \"nfaces\": nfaces\n",
    "        })\n",
    "        image_records.extend(result_records)\n",
    "        \n",
    "    \n",
    "    clear_output()\n",
    "    return pd.DataFrame(video_records), pd.DataFrame(image_records), pd.DataFrame(indices_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade7dabe-0944-4d81-a048-443756ddc558",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/data/konrad/workspace\"\n",
    "root_dir = f\"/data/data_calves/konrad\"\n",
    "\n",
    "yolo_id = 7\n",
    "yolo_face = YOLO(ROOT_DIR + f\"/models/best-face{yolo_id}.pt\")\n",
    "yolo_world = YOLO(\"yolov8s-world.pt\")  \n",
    "yolo_world.set_classes([\"calf face\"])\n",
    "\n",
    "aptm_sampled = pd.read_csv(f\"{root_dir}/usable_aptm_events.csv\")\n",
    "mp4_files = pd.read_csv(f\"{root_dir}/mp4_files.csv\")\n",
    "\n",
    "aptm_sampled[\"datetime\"] = pd.to_datetime(aptm_sampled[\"datetime\"])\n",
    "mp4_files[\"start_time\"] = pd.to_datetime(mp4_files[\"start_time\"])\n",
    "mp4_files[\"end_time\"] = pd.to_datetime(mp4_files[\"end_time\"])\n",
    "mp4_files[\"start_date\"] = mp4_files[\"start_time\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7230e7be-b1fe-463f-afd9-c98489343c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|                                                                        | 0/3854 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 2.8ms\n",
      "1: 384x640 (no detections), 2.8ms\n",
      "2: 384x640 (no detections), 2.8ms\n",
      "3: 384x640 (no detections), 2.8ms\n",
      "4: 384x640 1 Face, 2.8ms\n",
      "5: 384x640 1 Face, 2.8ms\n",
      "6: 384x640 (no detections), 2.8ms\n",
      "7: 384x640 (no detections), 2.8ms\n",
      "8: 384x640 (no detections), 2.8ms\n",
      "9: 384x640 1 Face, 2.8ms\n",
      "10: 384x640 (no detections), 2.8ms\n",
      "11: 384x640 (no detections), 2.8ms\n",
      "12: 384x640 (no detections), 2.8ms\n",
      "13: 384x640 (no detections), 2.8ms\n",
      "14: 384x640 (no detections), 2.8ms\n",
      "15: 384x640 (no detections), 2.8ms\n",
      "16: 384x640 (no detections), 2.8ms\n",
      "17: 384x640 (no detections), 2.8ms\n",
      "18: 384x640 (no detections), 2.8ms\n",
      "19: 384x640 (no detections), 2.8ms\n",
      "20: 384x640 (no detections), 2.8ms\n",
      "21: 384x640 1 Face, 2.8ms\n",
      "22: 384x640 1 Face, 2.8ms\n",
      "23: 384x640 (no detections), 2.8ms\n",
      "24: 384x640 (no detections), 2.8ms\n",
      "25: 384x640 (no detections), 2.8ms\n",
      "26: 384x640 (no detections), 2.8ms\n",
      "27: 384x640 (no detections), 2.8ms\n",
      "28: 384x640 (no detections), 2.8ms\n",
      "29: 384x640 (no detections), 2.8ms\n",
      "Speed: 1.3ms preprocess, 2.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|                                                             | 1/3854 [00:11<11:55:22, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Face, 0.3ms\n",
      "1: 384x640 (no detections), 0.3ms\n",
      "2: 384x640 1 Face, 0.3ms\n",
      "3: 384x640 1 Face, 0.3ms\n",
      "4: 384x640 1 Face, 0.3ms\n",
      "5: 384x640 1 Face, 0.3ms\n",
      "6: 384x640 1 Face, 0.3ms\n",
      "7: 384x640 1 Face, 0.3ms\n",
      "8: 384x640 1 Face, 0.3ms\n",
      "9: 384x640 1 Face, 0.3ms\n",
      "10: 384x640 (no detections), 0.3ms\n",
      "11: 384x640 (no detections), 0.3ms\n",
      "12: 384x640 (no detections), 0.3ms\n",
      "13: 384x640 (no detections), 0.3ms\n",
      "14: 384x640 (no detections), 0.3ms\n",
      "15: 384x640 (no detections), 0.3ms\n",
      "16: 384x640 1 Face, 0.3ms\n",
      "17: 384x640 1 Face, 0.3ms\n",
      "18: 384x640 1 Face, 0.3ms\n",
      "19: 384x640 1 Face, 0.3ms\n",
      "20: 384x640 1 Face, 0.3ms\n",
      "21: 384x640 1 Face, 0.3ms\n",
      "22: 384x640 1 Face, 0.3ms\n",
      "23: 384x640 1 Face, 0.3ms\n",
      "24: 384x640 (no detections), 0.3ms\n",
      "25: 384x640 (no detections), 0.3ms\n",
      "26: 384x640 (no detections), 0.3ms\n",
      "27: 384x640 (no detections), 0.3ms\n",
      "28: 384x640 (no detections), 0.3ms\n",
      "29: 384x640 (no detections), 0.3ms\n",
      "Speed: 1.1ms preprocess, 0.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing items:   0%|                                                             | 2/3854 [00:30<16:17:10, 15.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m root_dir \u001b[38;5;241m=\u001b[39m ROOT_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datasets/mixed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms_b\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# root_dir = f\"/data/data_calves/konrad/mixed_{frame}s_b{step}s\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# root_dir = f\"/data/data_calves/konrad/mixed_{frame}s_b{step}s_{timestamp}\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# root_dir = ROOT_DIR + \"/datasets/videos/train\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[43mextract_medias\u001b[49m\u001b[43m(\u001b[49m\u001b[43maptm_sampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmp4_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_sample_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mframe_sample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myolo_world\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myolo_face\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_conf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mibbox_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvbbox_conf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# records = extract_medias(aptm_sampled.iloc[:10], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, video_model = yolo_world, image_model = yolo_face, bbox_conf = (ibbox_conf, vbbox_conf))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# records = extract_videos_mdetr(aptm_sampled.iloc[:100], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# records = extract_videos(aptm_sampled.iloc[:100], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# End time\u001b[39;00m\n\u001b[1;32m     27\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36mextract_medias\u001b[0;34m(aptms, mp4_files, root_dir, frame_sample_rate, num_images, bbox_conf, delta, step, video_model, image_model)\u001b[0m\n\u001b[1;32m     48\u001b[0m nfaces \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tmpfile:\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_videofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmpfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     container \u001b[38;5;241m=\u001b[39m av\u001b[38;5;241m.\u001b[39mopen(tmpfile\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     54\u001b[0m     video_stream \u001b[38;5;241m=\u001b[39m container\u001b[38;5;241m.\u001b[39mstreams\u001b[38;5;241m.\u001b[39mvideo[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m<decorator-gen-73>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-72>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/decorators.py:135\u001b[0m, in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    130\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m    131\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[1;32m    132\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    133\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m k\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-71>:2\u001b[0m, in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/decorators.py:22\u001b[0m, in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mismask:\n\u001b[1;32m     21\u001b[0m     clip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mto_RGB()\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/video/VideoClip.py:300\u001b[0m, in \u001b[0;36mVideoClip.write_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m make_audio:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mwrite_audiofile(audiofile, audio_fps,\n\u001b[1;32m    294\u001b[0m                                audio_nbytes, audio_bufsize,\n\u001b[1;32m    295\u001b[0m                                audio_codec, bitrate\u001b[38;5;241m=\u001b[39maudio_bitrate,\n\u001b[1;32m    296\u001b[0m                                write_logfile\u001b[38;5;241m=\u001b[39mwrite_logfile,\n\u001b[1;32m    297\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    298\u001b[0m                                logger\u001b[38;5;241m=\u001b[39mlogger)\n\u001b[0;32m--> 300\u001b[0m \u001b[43mffmpeg_write_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbitrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwrite_logfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_logfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maudiofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudiofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_temp \u001b[38;5;129;01mand\u001b[39;00m make_audio:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(audiofile):\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_writer.py:220\u001b[0m, in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FFMPEG_VideoWriter(filename, clip\u001b[38;5;241m.\u001b[39msize, fps, codec \u001b[38;5;241m=\u001b[39m codec,\n\u001b[1;32m    214\u001b[0m                             preset\u001b[38;5;241m=\u001b[39mpreset, bitrate\u001b[38;5;241m=\u001b[39mbitrate, logfile\u001b[38;5;241m=\u001b[39mlogfile,\n\u001b[1;32m    215\u001b[0m                             audiofile\u001b[38;5;241m=\u001b[39maudiofile, threads\u001b[38;5;241m=\u001b[39mthreads,\n\u001b[1;32m    216\u001b[0m                             ffmpeg_params\u001b[38;5;241m=\u001b[39mffmpeg_params) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m    218\u001b[0m     nframes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(clip\u001b[38;5;241m.\u001b[39mduration\u001b[38;5;241m*\u001b[39mfps)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t,frame \u001b[38;5;129;01min\u001b[39;00m clip\u001b[38;5;241m.\u001b[39miter_frames(logger\u001b[38;5;241m=\u001b[39mlogger, with_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m                                     fps\u001b[38;5;241m=\u001b[39mfps, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m withmask:\n\u001b[1;32m    223\u001b[0m             mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m255\u001b[39m\u001b[38;5;241m*\u001b[39mclip\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mget_frame(t))\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/Clip.py:472\u001b[0m, in \u001b[0;36mClip.iter_frames\u001b[0;34m(self, fps, with_times, logger, dtype)\u001b[0m\n\u001b[1;32m    470\u001b[0m logger \u001b[38;5;241m=\u001b[39m proglog\u001b[38;5;241m.\u001b[39mdefault_bar_logger(logger)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m logger\u001b[38;5;241m.\u001b[39miter_bar(t\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration, \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39mfps)):\n\u001b[0;32m--> 472\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (frame\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype):\n\u001b[1;32m    474\u001b[0m         frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/Clip.py:136\u001b[0m, in \u001b[0;36mClip.fl.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    133\u001b[0m     apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#mf = copy(self.make_frame)\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m newclip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_make_frame(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_duration:\n\u001b[1;32m    139\u001b[0m     newclip\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/Clip.py:187\u001b[0m, in \u001b[0;36mClip.fl_time.<locals>.<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m apply_to \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     apply_to \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfl(\u001b[38;5;28;01mlambda\u001b[39;00m gf, t: \u001b[43mgf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, apply_to,\n\u001b[1;32m    188\u001b[0m                keep_duration\u001b[38;5;241m=\u001b[39mkeep_duration)\n",
      "File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[38;5;241m=\u001b[39m [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[38;5;241m=\u001b[39m {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m kw\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/video/io/VideoFileClip.py:113\u001b[0m, in \u001b[0;36mVideoFileClip.__init__.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Make a reader for the audio, if any.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39minfos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_found\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_reader.py:184\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_frames(pos\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m=\u001b[39m pos\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/x_env/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_reader.py:120\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.read_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m w, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m    118\u001b[0m nbytes\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth\u001b[38;5;241m*\u001b[39mw\u001b[38;5;241m*\u001b[39mh\n\u001b[0;32m--> 120\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m!=\u001b[39m nbytes:\n\u001b[1;32m    123\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: in file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename)\u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    124\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m bytes wanted but \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m bytes read,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(nbytes, \u001b[38;5;28mlen\u001b[39m(s))\u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    125\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mat frame \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, at time \u001b[39m\u001b[38;5;132;01m%.02f\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%.02f\u001b[39;00m\u001b[38;5;124m sec. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the last valid frame instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m            \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "frame = 10\n",
    "step = 0\n",
    "frame_sample_rate = 15\n",
    "num_images = 30\n",
    "ibbox_conf = .80\n",
    "vbbox_conf = .50\n",
    "delta = frame + step\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "timestamp = f\"y{yolo_id}_{current_datetime}\"\n",
    "# root_dir = ROOT_DIR + f\"/datasets/mixed_{frame}s_b{step}s_{timestamp}\"\n",
    "# root_dir = f\"/data/data_calves/konrad/mixed_{frame}s_b{step}s\"\n",
    "root_dir = f\"/data/data_calves/konrad/mixed_{frame}s_b{step}s_{timestamp}\"\n",
    "# root_dir = ROOT_DIR + \"/datasets/videos/train\"\n",
    "\n",
    "records = extract_medias(aptm_sampled, mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, video_model = yolo_world, image_model = yolo_face, bbox_conf = (ibbox_conf, vbbox_conf))\n",
    "# records = extract_medias(aptm_sampled.iloc[:10], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, video_model = yolo_world, image_model = yolo_face, bbox_conf = (ibbox_conf, vbbox_conf))\n",
    "# records = extract_videos_mdetr(aptm_sampled.iloc[:100], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\n",
    "# records = extract_videos(aptm_sampled.iloc[:100], mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\n",
    "# records = extract_videos(aptm_sampled, mp4_files, root_dir, delta = delta, step = step, frame_sample_rate = frame_sample_rate, num_images = num_images, model = yolo, bbox_conf = bbox_conf)\n",
    "# records = extract_videos(aptm_sampled.iloc[:10], mp4_files, root_dir, delta = delta, step = step)\n",
    "# records = extract_videos(aptm_sampled, mp4_files, root_dir, delta = delta, step = step)\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "formatted_time = format_time(elapsed_time)\n",
    "records[0].to_csv(root_dir + '/videos_metadata.csv', index=False)\n",
    "records[1].to_csv(root_dir + '/images_metadata.csv', index=False)\n",
    "records[2].to_csv(root_dir + '/indices_metadata.csv', index=False)\n",
    "# records.to_csv('train_video_extracted_metadata.csv', index=False)\n",
    "\n",
    "# Display the elapsed time\n",
    "print(f\"Time of execution: {formatted_time} from {elapsed_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (main_env)",
   "language": "python",
   "name": "x_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
